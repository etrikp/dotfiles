{"mode":"editor","version":1,"windowDimensions":{"x":193,"y":117,"width":1864,"height":1189,"maximized":false},"syntax":{"deserializer":"Syntax","grammarOverridesByPath":{}},"project":{"path":"/Users/etrikp/git/ansible","buffers":[{"text":"# This code is part of Ansible, but is an independent component.\n# This particular file snippet, and this file snippet only, is BSD licensed.\n# Modules you write using this snippet, which is embedded dynamically by Ansible\n# still belong to the author of the module, and may assign their own license\n# to the complete work.\n#\n# Copyright (c) 2014 Hewlett-Packard Development Company, L.P.\n# All rights reserved.\n#\n# Redistribution and use in source and binary forms, with or without modification,\n# are permitted provided that the following conditions are met:\n#\n#    * Redistributions of source code must retain the above copyright\n#      notice, this list of conditions and the following disclaimer.\n#    * Redistributions in binary form must reproduce the above copyright notice,\n#      this list of conditions and the following disclaimer in the documentation\n#      and/or other materials provided with the distribution.\n#\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\n# ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n# WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n# IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,\n# INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,\n# PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT\n# LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE\n# USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\nimport os\n\n\ndef openstack_argument_spec():\n    # Consume standard OpenStack environment variables.\n    # This is mainly only useful for ad-hoc command line operation as\n    # in playbooks one would assume variables would be used appropriately\n    OS_AUTH_URL=os.environ.get('OS_AUTH_URL', 'http://127.0.0.1:35357/v2.0/')\n    OS_PASSWORD=os.environ.get('OS_PASSWORD', None)\n    OS_REGION_NAME=os.environ.get('OS_REGION_NAME', None)\n    OS_USERNAME=os.environ.get('OS_USERNAME', 'admin')\n    OS_TENANT_NAME=os.environ.get('OS_TENANT_NAME', OS_USERNAME)\n\n    spec = dict(\n        login_username                  = dict(default=OS_USERNAME),\n        auth_url                        = dict(default=OS_AUTH_URL),\n        region_name                     = dict(default=OS_REGION_NAME),\n        availability_zone               = dict(default=None),\n    )\n    if OS_PASSWORD:\n        spec['login_password'] = dict(default=OS_PASSWORD)\n    else:\n        spec['login_password'] = dict(required=True)\n    if OS_TENANT_NAME:\n        spec['login_tenant_name'] = dict(default=OS_TENANT_NAME)\n    else:\n        spec['login_tenant_name'] = dict(required=True)\n    return spec\n\ndef openstack_find_nova_addresses(addresses, ext_tag, key_name=None):\n\n    ret = []\n    for (k, v) in addresses.iteritems():\n        if key_name and k == key_name:\n            ret.extend([addrs['addr'] for addrs in v])\n        else:\n            for interface_spec in v:\n                if 'OS-EXT-IPS:type' in interface_spec and interface_spec['OS-EXT-IPS:type'] == ext_tag:\n                    ret.append(interface_spec['addr'])\n    return ret\n\n","markers":{"markers":{"1":{"id":1,"range":[[0,0],[0,0]],"tailed":false,"reversed":false,"valid":true,"invalidate":"never","persistent":true,"properties":{"type":"selection","editorId":182},"deserializer":"Marker"}},"deserializer":"MarkerManager"},"history":{"undoStack":[],"redoStack":[],"deserializer":"History"},"filePath":"/Users/etrikp/git/ansible/lib/ansible/module_utils/openstack.py","modifiedWhenLastPersisted":false,"digestWhenLastPersisted":"4a063aad8cb8e7c0137fd4e6eeae82bb58cb1092","deserializer":"TextBuffer"},{"text":"# (c) 2012, Michael DeHaan <michael.dehaan@gmail.com>\n#\n# This file is part of Ansible\n#\n# Ansible is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# Ansible is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.\n\nimport os\nimport stat\nimport array\nimport errno\nimport fcntl\nimport fnmatch\nimport glob\nimport platform\nimport re\nimport signal\nimport socket\nimport struct\nimport datetime\nimport getpass\nimport ConfigParser\nimport StringIO\n\nfrom string import maketrans\n\ntry:\n    import selinux\n    HAVE_SELINUX=True\nexcept ImportError:\n    HAVE_SELINUX=False\n\ntry:\n    import json\nexcept ImportError:\n    import simplejson as json\n\n# --------------------------------------------------------------\n# timeout function to make sure some fact gathering \n# steps do not exceed a time limit\n\nclass TimeoutError(Exception):\n    pass\n\ndef timeout(seconds=10, error_message=\"Timer expired\"):\n    def decorator(func):\n        def _handle_timeout(signum, frame):\n            raise TimeoutError(error_message)\n\n        def wrapper(*args, **kwargs):\n            signal.signal(signal.SIGALRM, _handle_timeout)\n            signal.alarm(seconds)\n            try:\n                result = func(*args, **kwargs)\n            finally:\n                signal.alarm(0)\n            return result\n\n        return wrapper\n\n    return decorator\n\n# --------------------------------------------------------------\n\nclass Facts(object):\n    \"\"\"\n    This class should only attempt to populate those facts that\n    are mostly generic to all systems.  This includes platform facts,\n    service facts (e.g. ssh keys or selinux), and distribution facts.\n    Anything that requires extensive code or may have more than one\n    possible implementation to establish facts for a given topic should\n    subclass Facts.\n    \"\"\"\n\n    _I386RE = re.compile(r'i[3456]86')\n    # For the most part, we assume that platform.dist() will tell the truth.\n    # This is the fallback to handle unknowns or exceptions\n    OSDIST_DICT = { '/etc/redhat-release': 'RedHat',\n                    '/etc/vmware-release': 'VMwareESX',\n                    '/etc/openwrt_release': 'OpenWrt',\n                    '/etc/system-release': 'OtherLinux',\n                    '/etc/alpine-release': 'Alpine',\n                    '/etc/release': 'Solaris',\n                    '/etc/arch-release': 'Archlinux',\n                    '/etc/SuSE-release': 'SuSE',\n                    '/etc/gentoo-release': 'Gentoo',\n                    '/etc/os-release': 'Debian' }\n    SELINUX_MODE_DICT = { 1: 'enforcing', 0: 'permissive', -1: 'disabled' }\n\n    # A list of dicts.  If there is a platform with more than one\n    # package manager, put the preferred one last.  If there is an\n    # ansible module, use that as the value for the 'name' key.\n    PKG_MGRS = [ { 'path' : '/usr/bin/yum',         'name' : 'yum' },\n                 { 'path' : '/usr/bin/apt-get',     'name' : 'apt' },\n                 { 'path' : '/usr/bin/zypper',      'name' : 'zypper' },\n                 { 'path' : '/usr/sbin/urpmi',      'name' : 'urpmi' },\n                 { 'path' : '/usr/bin/pacman',      'name' : 'pacman' },\n                 { 'path' : '/bin/opkg',            'name' : 'opkg' },\n                 { 'path' : '/opt/local/bin/pkgin', 'name' : 'pkgin' },\n                 { 'path' : '/opt/local/bin/port',  'name' : 'macports' },\n                 { 'path' : '/sbin/apk',            'name' : 'apk' },\n                 { 'path' : '/usr/sbin/pkg',        'name' : 'pkgng' },\n                 { 'path' : '/usr/sbin/swlist',     'name' : 'SD-UX' },\n                 { 'path' : '/usr/bin/emerge',      'name' : 'portage' },\n                 { 'path' : '/usr/sbin/pkgadd',     'name' : 'svr4pkg' },\n                 { 'path' : '/usr/bin/pkg',         'name' : 'pkg' },\n    ]\n\n    def __init__(self):\n        self.facts = {}\n        self.get_platform_facts()\n        self.get_distribution_facts()\n        self.get_cmdline()\n        self.get_public_ssh_host_keys()\n        self.get_selinux_facts()\n        self.get_pkg_mgr_facts()\n        self.get_lsb_facts()\n        self.get_date_time_facts()\n        self.get_user_facts()\n        self.get_local_facts()\n        self.get_env_facts()\n\n    def populate(self):\n        return self.facts\n\n    # Platform\n    # platform.system() can be Linux, Darwin, Java, or Windows\n    def get_platform_facts(self):\n        self.facts['system'] = platform.system()\n        self.facts['kernel'] = platform.release()\n        self.facts['machine'] = platform.machine()\n        self.facts['python_version'] = platform.python_version()\n        self.facts['fqdn'] = socket.getfqdn()\n        self.facts['hostname'] = platform.node().split('.')[0]\n        self.facts['nodename'] = platform.node()\n        self.facts['domain'] = '.'.join(self.facts['fqdn'].split('.')[1:])\n        arch_bits = platform.architecture()[0]\n        self.facts['userspace_bits'] = arch_bits.replace('bit', '')\n        if self.facts['machine'] == 'x86_64':\n            self.facts['architecture'] = self.facts['machine']\n            if self.facts['userspace_bits'] == '64':\n                self.facts['userspace_architecture'] = 'x86_64'\n            elif self.facts['userspace_bits'] == '32':\n                self.facts['userspace_architecture'] = 'i386'\n        elif Facts._I386RE.search(self.facts['machine']):\n            self.facts['architecture'] = 'i386'\n            if self.facts['userspace_bits'] == '64':\n                self.facts['userspace_architecture'] = 'x86_64'\n            elif self.facts['userspace_bits'] == '32':\n                self.facts['userspace_architecture'] = 'i386'\n        else:\n            self.facts['architecture'] = self.facts['machine']\n        if self.facts['system'] == 'Linux':\n            self.get_distribution_facts()\n        elif self.facts['system'] == 'AIX':\n            rc, out, err = module.run_command(\"/usr/sbin/bootinfo -p\")\n            data = out.split('\\n')\n            self.facts['architecture'] = data[0]\n\n\n    def get_local_facts(self):\n\n        fact_path = module.params.get('fact_path', None)\n        if not fact_path or not os.path.exists(fact_path):\n            return\n\n        local = {}\n        for fn in sorted(glob.glob(fact_path + '/*.fact')):\n            # where it will sit under local facts\n            fact_base = os.path.basename(fn).replace('.fact','')\n            if stat.S_IXUSR & os.stat(fn)[stat.ST_MODE]:\n                # run it\n                # try to read it as json first\n                # if that fails read it with ConfigParser\n                # if that fails, skip it\n                rc, out, err = module.run_command(fn)\n            else:\n                out = open(fn).read()\n\n            # load raw json\n            fact = 'loading %s' % fact_base\n            try:\n                fact = json.loads(out)\n            except ValueError, e:\n                # load raw ini\n                cp = ConfigParser.ConfigParser()\n                try:\n                    cp.readfp(StringIO.StringIO(out))\n                except ConfigParser.Error, e:\n                    fact=\"error loading fact - please check content\"\n                else:\n                    fact = {}\n                    #print cp.sections()\n                    for sect in cp.sections():\n                        if sect not in fact:\n                            fact[sect] = {}\n                        for opt in cp.options(sect):\n                            val = cp.get(sect, opt)\n                            fact[sect][opt]=val\n\n            local[fact_base] = fact\n        if not local:\n            return\n        self.facts['local'] = local\n\n    # platform.dist() is deprecated in 2.6\n    # in 2.6 and newer, you should use platform.linux_distribution()\n    def get_distribution_facts(self):\n\n        # A list with OS Family members\n        OS_FAMILY = dict(\n            RedHat = 'RedHat', Fedora = 'RedHat', CentOS = 'RedHat', Scientific = 'RedHat',\n            SLC = 'RedHat', Ascendos = 'RedHat', CloudLinux = 'RedHat', PSBM = 'RedHat',\n            OracleLinux = 'RedHat', OVS = 'RedHat', OEL = 'RedHat', Amazon = 'RedHat',\n            XenServer = 'RedHat', Ubuntu = 'Debian', Debian = 'Debian', SLES = 'Suse',\n            SLED = 'Suse', OpenSuSE = 'Suse', SuSE = 'Suse', Gentoo = 'Gentoo', Funtoo = 'Gentoo',\n            Archlinux = 'Archlinux', Mandriva = 'Mandrake', Mandrake = 'Mandrake',\n            Solaris = 'Solaris', Nexenta = 'Solaris', OmniOS = 'Solaris', OpenIndiana = 'Solaris',\n            SmartOS = 'Solaris', AIX = 'AIX', Alpine = 'Alpine', MacOSX = 'Darwin',\n            FreeBSD = 'FreeBSD', HPUX = 'HP-UX'\n        )\n\n        if self.facts['system'] == 'AIX':\n            self.facts['distribution'] = 'AIX'\n            rc, out, err = module.run_command(\"/usr/bin/oslevel\")\n            data = out.split('.')\n            self.facts['distribution_version'] = data[0]\n            self.facts['distribution_release'] = data[1]\n        elif self.facts['system'] == 'HP-UX':\n            self.facts['distribution'] = 'HP-UX'\n            rc, out, err = module.run_command(\"/usr/sbin/swlist |egrep 'HPUX.*OE.*[AB].[0-9]+\\.[0-9]+'\", use_unsafe_shell=True)\n            data = re.search('HPUX.*OE.*([AB].[0-9]+\\.[0-9]+)\\.([0-9]+).*', out)\n            if data:\n                self.facts['distribution_version'] = data.groups()[0]\n                self.facts['distribution_release'] = data.groups()[1]\n        elif self.facts['system'] == 'Darwin':\n            self.facts['distribution'] = 'MacOSX'\n            rc, out, err = module.run_command(\"/usr/bin/sw_vers -productVersion\")\n            data = out.split()[-1]\n            self.facts['distribution_version'] = data\n        elif self.facts['system'] == 'FreeBSD':\n            self.facts['distribution'] = 'FreeBSD'\n            self.facts['distribution_release'] = platform.release()\n            self.facts['distribution_version'] = platform.version()\n        elif self.facts['system'] == 'OpenBSD':\n            self.facts['distribution'] = 'OpenBSD'\n            self.facts['distribution_release'] = platform.release()\n            rc, out, err = module.run_command(\"/sbin/sysctl -n kern.version\")\n            match = re.match('OpenBSD\\s[0-9]+.[0-9]+-(\\S+)\\s.*', out)\n            if match:\n                self.facts['distribution_version'] = match.groups()[0]\n            else:\n                self.facts['distribution_version'] = 'release'\n        else:\n            dist = platform.dist()\n            self.facts['distribution'] = dist[0].capitalize() or 'NA'\n            self.facts['distribution_version'] = dist[1] or 'NA'\n            self.facts['distribution_major_version'] = dist[1].split('.')[0] or 'NA'\n            self.facts['distribution_release'] = dist[2] or 'NA'\n            # Try to handle the exceptions now ...\n            for (path, name) in Facts.OSDIST_DICT.items():\n                if os.path.exists(path) and os.path.getsize(path) > 0:\n                    if self.facts['distribution'] == 'Fedora':\n                        pass\n                    elif name == 'RedHat':\n                        data = get_file_content(path)\n                        if 'Red Hat' in data:\n                            self.facts['distribution'] = name\n                        else:\n                            self.facts['distribution'] = data.split()[0]\n                    elif name == 'OtherLinux':\n                        data = get_file_content(path)\n                        if 'Amazon' in data:\n                            self.facts['distribution'] = 'Amazon'\n                            self.facts['distribution_version'] = data.split()[-1]\n                    elif name == 'OpenWrt':\n                        data = get_file_content(path)\n                        if 'OpenWrt' in data:\n                            self.facts['distribution'] = name\n                        version = re.search('DISTRIB_RELEASE=\"(.*)\"', data)\n                        if version:\n                            self.facts['distribution_version'] = version.groups()[0]\n                        release = re.search('DISTRIB_CODENAME=\"(.*)\"', data)\n                        if release:\n                            self.facts['distribution_release'] = release.groups()[0]\n                    elif name == 'Alpine':\n                        data = get_file_content(path)\n                        self.facts['distribution'] = 'Alpine'\n                        self.facts['distribution_version'] = data\n                    elif name == 'Solaris':\n                        data = get_file_content(path).split('\\n')[0]\n                        ora_prefix = ''\n                        if 'Oracle Solaris' in data:\n                            data = data.replace('Oracle ','')\n                            ora_prefix = 'Oracle '\n                        self.facts['distribution'] = data.split()[0]\n                        self.facts['distribution_version'] = data.split()[1]\n                        self.facts['distribution_release'] = ora_prefix + data\n                    elif name == 'SuSE':\n                        data = get_file_content(path).splitlines()\n                        for line in data:\n                            if '=' in line:\n                            \tself.facts['distribution_release'] = line.split('=')[1].strip()\n                    elif name == 'Debian':\n                        data = get_file_content(path).split('\\n')[0]\n                        release = re.search(\"PRETTY_NAME.+ \\(?([^ ]+?)\\)?\\\"\", data)\n                        if release:\n                            self.facts['distribution_release'] = release.groups()[0]\n                    else:\n                        self.facts['distribution'] = name\n\n        self.facts['os_family'] = self.facts['distribution']\n        if self.facts['distribution'] in OS_FAMILY:\n            self.facts['os_family'] = OS_FAMILY[self.facts['distribution']]\n\n    def get_cmdline(self):\n        data = get_file_content('/proc/cmdline')\n        if data:\n            self.facts['cmdline'] = {}\n            try:\n                for piece in shlex.split(data):\n                    item = piece.split('=', 1)\n                    if len(item) == 1:\n                        self.facts['cmdline'][item[0]] = True\n                    else:\n                        self.facts['cmdline'][item[0]] = item[1]\n            except ValueError, e:\n                pass\n\n    def get_public_ssh_host_keys(self):\n        dsa_filename = '/etc/ssh/ssh_host_dsa_key.pub'\n        rsa_filename = '/etc/ssh/ssh_host_rsa_key.pub'\n        ecdsa_filename = '/etc/ssh/ssh_host_ecdsa_key.pub'\n\n        if self.facts['system'] == 'Darwin':\n            dsa_filename = '/etc/ssh_host_dsa_key.pub'\n            rsa_filename = '/etc/ssh_host_rsa_key.pub'\n            ecdsa_filename = '/etc/ssh_host_ecdsa_key.pub'\n        dsa = get_file_content(dsa_filename)\n        rsa = get_file_content(rsa_filename)\n        ecdsa = get_file_content(ecdsa_filename)\n        if dsa is None:\n            dsa = 'NA'\n        else:\n            self.facts['ssh_host_key_dsa_public'] = dsa.split()[1]\n        if rsa is None:\n            rsa = 'NA'\n        else:\n            self.facts['ssh_host_key_rsa_public'] = rsa.split()[1]\n        if ecdsa is None:\n            ecdsa = 'NA'\n        else:\n            self.facts['ssh_host_key_ecdsa_public'] = ecdsa.split()[1]\n\n    def get_pkg_mgr_facts(self):\n        self.facts['pkg_mgr'] = 'unknown'\n        for pkg in Facts.PKG_MGRS:\n            if os.path.exists(pkg['path']):\n                self.facts['pkg_mgr'] = pkg['name']\n        if self.facts['system'] == 'OpenBSD':\n                self.facts['pkg_mgr'] = 'openbsd_pkg'\n\n    def get_lsb_facts(self):\n        lsb_path = module.get_bin_path('lsb_release')\n        if lsb_path:\n            rc, out, err = module.run_command([lsb_path, \"-a\"])\n            if rc == 0:\n                self.facts['lsb'] = {}\n            for line in out.split('\\n'):\n                if len(line) < 1:\n                    continue\n                value = line.split(':', 1)[1].strip()\n                if 'LSB Version:' in line:\n                    self.facts['lsb']['release'] = value\n                elif 'Distributor ID:' in line:\n                    self.facts['lsb']['id'] = value\n                elif 'Description:' in line:\n                    self.facts['lsb']['description'] = value\n                elif 'Release:' in line:\n                    self.facts['lsb']['release'] = value\n                elif 'Codename:' in line:\n                    self.facts['lsb']['codename'] = value\n            if 'lsb' in self.facts and 'release' in self.facts['lsb']:\n                self.facts['lsb']['major_release'] = self.facts['lsb']['release'].split('.')[0]\n        elif lsb_path is None and os.path.exists('/etc/lsb-release'):\n            self.facts['lsb'] = {}\n            f = open('/etc/lsb-release', 'r')\n            try:\n                for line in f.readlines():\n                    value = line.split('=',1)[1].strip()\n                    if 'DISTRIB_ID' in line:\n                        self.facts['lsb']['id'] = value\n                    elif 'DISTRIB_RELEASE' in line:\n                        self.facts['lsb']['release'] = value\n                    elif 'DISTRIB_DESCRIPTION' in line:\n                        self.facts['lsb']['description'] = value\n                    elif 'DISTRIB_CODENAME' in line:\n                        self.facts['lsb']['codename'] = value\n            finally:\n                f.close()\n        else:\n            return self.facts\n\n        if 'lsb' in self.facts and 'release' in self.facts['lsb']:\n            self.facts['lsb']['major_release'] = self.facts['lsb']['release'].split('.')[0]\n\n\n    def get_selinux_facts(self):\n        if not HAVE_SELINUX:\n            self.facts['selinux'] = False\n            return\n        self.facts['selinux'] = {}\n        if not selinux.is_selinux_enabled():\n            self.facts['selinux']['status'] = 'disabled'\n        else:\n            self.facts['selinux']['status'] = 'enabled'\n            try:\n                self.facts['selinux']['policyvers'] = selinux.security_policyvers()\n            except OSError, e:\n                self.facts['selinux']['policyvers'] = 'unknown'\n            try:\n                (rc, configmode) = selinux.selinux_getenforcemode()\n                if rc == 0:\n                    self.facts['selinux']['config_mode'] = Facts.SELINUX_MODE_DICT.get(configmode, 'unknown')\n                else:\n                    self.facts['selinux']['config_mode'] = 'unknown'\n            except OSError, e:\n                self.facts['selinux']['config_mode'] = 'unknown'\n            try:\n                mode = selinux.security_getenforce()\n                self.facts['selinux']['mode'] = Facts.SELINUX_MODE_DICT.get(mode, 'unknown')\n            except OSError, e:\n                self.facts['selinux']['mode'] = 'unknown'\n            try:\n                (rc, policytype) = selinux.selinux_getpolicytype()\n                if rc == 0:\n                    self.facts['selinux']['type'] = policytype\n                else:\n                    self.facts['selinux']['type'] = 'unknown'\n            except OSError, e:\n                self.facts['selinux']['type'] = 'unknown'\n\n\n    def get_date_time_facts(self):\n        self.facts['date_time'] = {}\n\n        now = datetime.datetime.now()\n        self.facts['date_time']['year'] = now.strftime('%Y')\n        self.facts['date_time']['month'] = now.strftime('%m')\n        self.facts['date_time']['weekday'] = now.strftime('%A')\n        self.facts['date_time']['day'] = now.strftime('%d')\n        self.facts['date_time']['hour'] = now.strftime('%H')\n        self.facts['date_time']['minute'] = now.strftime('%M')\n        self.facts['date_time']['second'] = now.strftime('%S')\n        self.facts['date_time']['epoch'] = now.strftime('%s')\n        if self.facts['date_time']['epoch'] == '' or self.facts['date_time']['epoch'][0] == '%':\n            self.facts['date_time']['epoch'] = str(int(time.time()))\n        self.facts['date_time']['date'] = now.strftime('%Y-%m-%d')\n        self.facts['date_time']['time'] = now.strftime('%H:%M:%S')\n        self.facts['date_time']['iso8601_micro'] = now.utcnow().strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\")\n        self.facts['date_time']['iso8601'] = now.utcnow().strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n        self.facts['date_time']['tz'] = time.strftime(\"%Z\")\n        self.facts['date_time']['tz_offset'] = time.strftime(\"%z\")\n\n\n    # User\n    def get_user_facts(self):\n        self.facts['user_id'] = getpass.getuser()\n\n    def get_env_facts(self):\n        self.facts['env'] = {}\n        for k,v in os.environ.iteritems():\n            self.facts['env'][k] = v\n\nclass Hardware(Facts):\n    \"\"\"\n    This is a generic Hardware subclass of Facts.  This should be further\n    subclassed to implement per platform.  If you subclass this, it\n    should define:\n    - memfree_mb\n    - memtotal_mb\n    - swapfree_mb\n    - swaptotal_mb\n    - processor (a list)\n    - processor_cores\n    - processor_count\n\n    All subclasses MUST define platform.\n    \"\"\"\n    platform = 'Generic'\n\n    def __new__(cls, *arguments, **keyword):\n        subclass = cls\n        for sc in Hardware.__subclasses__():\n            if sc.platform == platform.system():\n                subclass = sc\n        return super(cls, subclass).__new__(subclass, *arguments, **keyword)\n\n    def __init__(self):\n        Facts.__init__(self)\n\n    def populate(self):\n        return self.facts\n\nclass LinuxHardware(Hardware):\n    \"\"\"\n    Linux-specific subclass of Hardware.  Defines memory and CPU facts:\n    - memfree_mb\n    - memtotal_mb\n    - swapfree_mb\n    - swaptotal_mb\n    - processor (a list)\n    - processor_cores\n    - processor_count\n\n    In addition, it also defines number of DMI facts and device facts.\n    \"\"\"\n\n    platform = 'Linux'\n    MEMORY_FACTS = ['MemTotal', 'SwapTotal', 'MemFree', 'SwapFree']\n\n    def __init__(self):\n        Hardware.__init__(self)\n\n    def populate(self):\n        self.get_cpu_facts()\n        self.get_memory_facts()\n        self.get_dmi_facts()\n        self.get_device_facts()\n        try:\n            self.get_mount_facts()\n        except TimeoutError:\n            pass\n        return self.facts\n\n    def get_memory_facts(self):\n        if not os.access(\"/proc/meminfo\", os.R_OK):\n            return\n        for line in open(\"/proc/meminfo\").readlines():\n            data = line.split(\":\", 1)\n            key = data[0]\n            if key in LinuxHardware.MEMORY_FACTS:\n                val = data[1].strip().split(' ')[0]\n                self.facts[\"%s_mb\" % key.lower()] = long(val) / 1024\n\n    def get_cpu_facts(self):\n        i = 0\n        physid = 0\n        coreid = 0\n        sockets = {}\n        cores = {}\n        if not os.access(\"/proc/cpuinfo\", os.R_OK):\n            return\n        self.facts['processor'] = []\n        for line in open(\"/proc/cpuinfo\").readlines():\n            data = line.split(\":\", 1)\n            key = data[0].strip()\n            # model name is for Intel arch, Processor (mind the uppercase P)\n            # works for some ARM devices, like the Sheevaplug.\n            if key == 'model name' or key == 'Processor' or key == 'vendor_id':\n                if 'processor' not in self.facts:\n                    self.facts['processor'] = []\n                self.facts['processor'].append(data[1].strip())\n                i += 1\n            elif key == 'physical id':\n                physid = data[1].strip()\n                if physid not in sockets:\n                    sockets[physid] = 1\n            elif key == 'core id':\n                coreid = data[1].strip()\n                if coreid not in sockets:\n                    cores[coreid] = 1\n            elif key == 'cpu cores':\n                sockets[physid] = int(data[1].strip())\n            elif key == 'siblings':\n                cores[coreid] = int(data[1].strip())\n            elif key == '# processors':\n                self.facts['processor_cores'] = int(data[1].strip())\n        if self.facts['architecture'] != 's390x':\n            self.facts['processor_count'] = sockets and len(sockets) or i\n            self.facts['processor_cores'] = sockets.values() and sockets.values()[0] or 1\n            self.facts['processor_threads_per_core'] = ((cores.values() and\n                cores.values()[0] or 1) / self.facts['processor_cores'])\n            self.facts['processor_vcpus'] = (self.facts['processor_threads_per_core'] *\n                self.facts['processor_count'] * self.facts['processor_cores'])\n\n    def get_dmi_facts(self):\n        ''' learn dmi facts from system\n\n        Try /sys first for dmi related facts.\n        If that is not available, fall back to dmidecode executable '''\n\n        if os.path.exists('/sys/devices/virtual/dmi/id/product_name'):\n            # Use kernel DMI info, if available\n\n            # DMI SPEC -- http://www.dmtf.org/sites/default/files/standards/documents/DSP0134_2.7.0.pdf\n            FORM_FACTOR = [ \"Unknown\", \"Other\", \"Unknown\", \"Desktop\",\n                            \"Low Profile Desktop\", \"Pizza Box\", \"Mini Tower\", \"Tower\",\n                            \"Portable\", \"Laptop\", \"Notebook\", \"Hand Held\", \"Docking Station\",\n                            \"All In One\", \"Sub Notebook\", \"Space-saving\", \"Lunch Box\",\n                            \"Main Server Chassis\", \"Expansion Chassis\", \"Sub Chassis\",\n                            \"Bus Expansion Chassis\", \"Peripheral Chassis\", \"RAID Chassis\",\n                            \"Rack Mount Chassis\", \"Sealed-case PC\", \"Multi-system\",\n                            \"CompactPCI\", \"AdvancedTCA\", \"Blade\" ]\n\n            DMI_DICT = {\n                    'bios_date': '/sys/devices/virtual/dmi/id/bios_date',\n                    'bios_version': '/sys/devices/virtual/dmi/id/bios_version',\n                    'form_factor': '/sys/devices/virtual/dmi/id/chassis_type',\n                    'product_name': '/sys/devices/virtual/dmi/id/product_name',\n                    'product_serial': '/sys/devices/virtual/dmi/id/product_serial',\n                    'product_uuid': '/sys/devices/virtual/dmi/id/product_uuid',\n                    'product_version': '/sys/devices/virtual/dmi/id/product_version',\n                    'system_vendor': '/sys/devices/virtual/dmi/id/sys_vendor'\n                    }\n\n            for (key,path) in DMI_DICT.items():\n                data = get_file_content(path)\n                if data is not None:\n                    if key == 'form_factor':\n                        try:\n                            self.facts['form_factor'] = FORM_FACTOR[int(data)]\n                        except IndexError, e:\n                            self.facts['form_factor'] = 'unknown (%s)' % data\n                    else:\n                        self.facts[key] = data\n                else:\n                    self.facts[key] = 'NA'\n\n        else:\n            # Fall back to using dmidecode, if available\n            dmi_bin = module.get_bin_path('dmidecode')\n            DMI_DICT = {\n                    'bios_date': 'bios-release-date',\n                    'bios_version': 'bios-version',\n                    'form_factor': 'chassis-type',\n                    'product_name': 'system-product-name',\n                    'product_serial': 'system-serial-number',\n                    'product_uuid': 'system-uuid',\n                    'product_version': 'system-version',\n                    'system_vendor': 'system-manufacturer'\n                    }\n            for (k, v) in DMI_DICT.items():\n                if dmi_bin is not None:\n                    (rc, out, err) = module.run_command('%s -s %s' % (dmi_bin, v))\n                    if rc == 0:\n                        # Strip out commented lines (specific dmidecode output)\n                        thisvalue = ''.join([ line for line in out.split('\\n') if not line.startswith('#') ])\n                        try:\n                            json.dumps(thisvalue)\n                        except UnicodeDecodeError:\n                            thisvalue = \"NA\"\n\n                        self.facts[k] = thisvalue\n                    else:\n                        self.facts[k] = 'NA'\n                else:\n                    self.facts[k] = 'NA'\n\n    @timeout(10)\n    def get_mount_facts(self):\n        self.facts['mounts'] = []\n        mtab = get_file_content('/etc/mtab', '')\n        for line in mtab.split('\\n'):\n            if line.startswith('/'):\n                fields = line.rstrip('\\n').split()\n                if(fields[2] != 'none'):\n                    size_total = None\n                    size_available = None\n                    try:\n                        statvfs_result = os.statvfs(fields[1])\n                        size_total = statvfs_result.f_bsize * statvfs_result.f_blocks\n                        size_available = statvfs_result.f_bsize * (statvfs_result.f_bavail)\n                    except OSError, e:\n                        continue\n\n                    self.facts['mounts'].append(\n                        {'mount': fields[1],\n                         'device':fields[0],\n                         'fstype': fields[2],\n                         'options': fields[3],\n                         # statvfs data\n                         'size_total': size_total,\n                         'size_available': size_available,\n                         })\n\n    def get_device_facts(self):\n        self.facts['devices'] = {}\n        lspci = module.get_bin_path('lspci')\n        if lspci:\n            rc, pcidata, err = module.run_command([lspci, '-D'])\n        else:\n            pcidata = None\n\n        try:\n            block_devs = os.listdir(\"/sys/block\")\n        except OSError:\n            return\n\n        for block in block_devs:\n            virtual = 1\n            sysfs_no_links = 0\n            try:\n                path = os.readlink(os.path.join(\"/sys/block/\", block))\n            except OSError, e:\n                if e.errno == errno.EINVAL:\n                    path = block\n                    sysfs_no_links = 1\n                else:\n                    continue\n            if \"virtual\" in path:\n                continue\n            sysdir = os.path.join(\"/sys/block\", path)\n            if sysfs_no_links == 1:\n                for folder in os.listdir(sysdir):\n                    if \"device\" in folder:\n                        virtual = 0\n                        break\n                if virtual:\n                    continue\n            d = {}\n            diskname = os.path.basename(sysdir)\n            for key in ['vendor', 'model']:\n                d[key] = get_file_content(sysdir + \"/device/\" + key)\n\n            for key,test in [ ('removable','/removable'), \\\n                              ('support_discard','/queue/discard_granularity'),\n                              ]:\n                d[key] = get_file_content(sysdir + test)\n\n            d['partitions'] = {}\n            for folder in os.listdir(sysdir):\n                m = re.search(\"(\" + diskname + \"\\d+)\", folder)\n                if m:\n                    part = {}\n                    partname = m.group(1)\n                    part_sysdir = sysdir + \"/\" + partname\n\n                    part['start'] = get_file_content(part_sysdir + \"/start\",0)\n                    part['sectors'] = get_file_content(part_sysdir + \"/size\",0)\n                    part['sectorsize'] = get_file_content(part_sysdir + \"/queue/physical_block_size\")\n                    if not part['sectorsize']:\n                        part['sectorsize'] = get_file_content(part_sysdir + \"/queue/hw_sector_size\",512)\n                    part['size'] = module.pretty_bytes((float(part['sectors']) * float(part['sectorsize'])))\n                    d['partitions'][partname] = part\n\n            d['rotational'] = get_file_content(sysdir + \"/queue/rotational\")\n            d['scheduler_mode'] = \"\"\n            scheduler = get_file_content(sysdir + \"/queue/scheduler\")\n            if scheduler is not None:\n                m = re.match(\".*?(\\[(.*)\\])\", scheduler)\n                if m:\n                    d['scheduler_mode'] = m.group(2)\n\n            d['sectors'] = get_file_content(sysdir + \"/size\")\n            if not d['sectors']:\n                d['sectors'] = 0\n            d['sectorsize'] = get_file_content(sysdir + \"/queue/physical_block_size\")\n            if not d['sectorsize']:\n                d['sectorsize'] = get_file_content(sysdir + \"/queue/hw_sector_size\",512)\n            d['size'] = module.pretty_bytes(float(d['sectors']) * float(d['sectorsize']))\n\n            d['host'] = \"\"\n\n            # domains are numbered (0 to ffff), bus (0 to ff), slot (0 to 1f), and function (0 to 7).\n            m = re.match(\".+/([a-f0-9]{4}:[a-f0-9]{2}:[0|1][a-f0-9]\\.[0-7])/\", sysdir)\n            if m and pcidata:\n                pciid = m.group(1)\n                did = re.escape(pciid)\n                m = re.search(\"^\" + did + \"\\s(.*)$\", pcidata, re.MULTILINE)\n                d['host'] = m.group(1)\n\n            d['holders'] = []\n            if os.path.isdir(sysdir + \"/holders\"):\n                for folder in os.listdir(sysdir + \"/holders\"):\n                    if not folder.startswith(\"dm-\"):\n                        continue\n                    name = get_file_content(sysdir + \"/holders/\" + folder + \"/dm/name\")\n                    if name:\n                        d['holders'].append(name)\n                    else:\n                        d['holders'].append(folder)\n\n            self.facts['devices'][diskname] = d\n\n\nclass SunOSHardware(Hardware):\n    \"\"\"\n    In addition to the generic memory and cpu facts, this also sets\n    swap_reserved_mb and swap_allocated_mb that is available from *swap -s*.\n    \"\"\"\n    platform = 'SunOS'\n\n    def __init__(self):\n        Hardware.__init__(self)\n\n    def populate(self):\n        self.get_cpu_facts()\n        self.get_memory_facts()\n        return self.facts\n\n    def get_cpu_facts(self):\n        physid = 0\n        sockets = {}\n        rc, out, err = module.run_command(\"/usr/bin/kstat cpu_info\")\n        self.facts['processor'] = []\n        for line in out.split('\\n'):\n            if len(line) < 1:\n                continue\n            data = line.split(None, 1)\n            key = data[0].strip()\n            # \"brand\" works on Solaris 10 & 11. \"implementation\" for Solaris 9.\n            if key == 'module:':\n                brand = ''\n            elif key == 'brand':\n                brand = data[1].strip()\n            elif key == 'clock_MHz':\n                clock_mhz = data[1].strip()\n            elif key == 'implementation':\n                processor = brand or data[1].strip()\n                # Add clock speed to description for SPARC CPU\n                if self.facts['machine'] != 'i86pc':\n                    processor += \" @ \" + clock_mhz + \"MHz\"\n                if 'processor' not in self.facts:\n                    self.facts['processor'] = []\n                self.facts['processor'].append(processor)\n            elif key == 'chip_id':\n                physid = data[1].strip()\n                if physid not in sockets:\n                    sockets[physid] = 1\n                else:\n                    sockets[physid] += 1\n        # Counting cores on Solaris can be complicated.\n        # https://blogs.oracle.com/mandalika/entry/solaris_show_me_the_cpu\n        # Treat 'processor_count' as physical sockets and 'processor_cores' as\n        # virtual CPUs visisble to Solaris. Not a true count of cores for modern SPARC as\n        # these processors have: sockets -> cores -> threads/virtual CPU.\n        if len(sockets) > 0:\n            self.facts['processor_count'] = len(sockets)\n            self.facts['processor_cores'] = reduce(lambda x, y: x + y, sockets.values())\n        else:\n            self.facts['processor_cores'] = 'NA'\n            self.facts['processor_count'] = len(self.facts['processor'])\n\n    def get_memory_facts(self):\n        rc, out, err = module.run_command([\"/usr/sbin/prtconf\"])\n        for line in out.split('\\n'):\n            if 'Memory size' in line:\n                self.facts['memtotal_mb'] = line.split()[2]\n        rc, out, err = module.run_command(\"/usr/sbin/swap -s\")\n        allocated = long(out.split()[1][:-1])\n        reserved = long(out.split()[5][:-1])\n        used = long(out.split()[8][:-1])\n        free = long(out.split()[10][:-1])\n        self.facts['swapfree_mb'] = free / 1024\n        self.facts['swaptotal_mb'] = (free + used) / 1024\n        self.facts['swap_allocated_mb'] = allocated / 1024\n        self.facts['swap_reserved_mb'] = reserved / 1024\n\nclass OpenBSDHardware(Hardware):\n    \"\"\"\n    OpenBSD-specific subclass of Hardware. Defines memory, CPU and device facts:\n    - memfree_mb\n    - memtotal_mb\n    - swapfree_mb\n    - swaptotal_mb\n    - processor (a list)\n    - processor_cores\n    - processor_count\n    - processor_speed\n    - devices\n    \"\"\"\n    platform = 'OpenBSD'\n    DMESG_BOOT = '/var/run/dmesg.boot'\n\n    def __init__(self):\n        Hardware.__init__(self)\n\n    def populate(self):\n        self.sysctl = self.get_sysctl()\n        self.get_memory_facts()\n        self.get_processor_facts()\n        self.get_device_facts()\n        return self.facts\n\n    def get_sysctl(self):\n        rc, out, err = module.run_command([\"/sbin/sysctl\", \"hw\"])\n        if rc != 0:\n            return dict()\n        sysctl = dict()\n        for line in out.splitlines():\n            (key, value) = line.split('=')\n            sysctl[key] = value.strip()\n        return sysctl\n\n    def get_memory_facts(self):\n        # Get free memory. vmstat output looks like:\n        #  procs    memory       page                    disks    traps          cpu\n        #  r b w    avm     fre  flt  re  pi  po  fr  sr wd0 fd0  int   sys   cs us sy id\n        #  0 0 0  47512   28160   51   0   0   0   0   0   1   0  116    89   17  0  1 99\n        rc, out, err = module.run_command(\"/usr/bin/vmstat\")\n        if rc == 0:\n            self.facts['memfree_mb'] = long(out.splitlines()[-1].split()[4]) / 1024\n            self.facts['memtotal_mb'] = long(self.sysctl['hw.usermem']) / 1024 / 1024\n\n        # Get swapctl info. swapctl output looks like:\n        # total: 69268 1K-blocks allocated, 0 used, 69268 available\n        # And for older OpenBSD:\n        # total: 69268k bytes allocated = 0k used, 69268k available\n        rc, out, err = module.run_command(\"/sbin/swapctl -sk\")\n        if rc == 0:\n            swaptrans = maketrans(' ', ' ')\n            data = out.split()\n            self.facts['swapfree_mb'] = long(data[-2].translate(swaptrans, \"kmg\")) / 1024\n            self.facts['swaptotal_mb'] = long(data[1].translate(swaptrans, \"kmg\")) / 1024\n\n    def get_processor_facts(self):\n        processor = []\n        dmesg_boot = get_file_content(OpenBSDHardware.DMESG_BOOT)\n        if not dmesg_boot:\n            rc, dmesg_boot, err = module.run_command(\"/sbin/dmesg\")\n        i = 0\n        for line in dmesg_boot.splitlines():\n            if line.split(' ', 1)[0] == 'cpu%i:' % i:\n                processor.append(line.split(' ', 1)[1])\n                i = i + 1\n        processor_count = i\n        self.facts['processor'] = processor\n        self.facts['processor_count'] = processor_count\n        # I found no way to figure out the number of Cores per CPU in OpenBSD\n        self.facts['processor_cores'] = 'NA'\n\n    def get_device_facts(self):\n        devices = []\n        devices.extend(self.sysctl['hw.disknames'].split(','))\n        self.facts['devices'] = devices\n\nclass FreeBSDHardware(Hardware):\n    \"\"\"\n    FreeBSD-specific subclass of Hardware.  Defines memory and CPU facts:\n    - memfree_mb\n    - memtotal_mb\n    - swapfree_mb\n    - swaptotal_mb\n    - processor (a list)\n    - processor_cores\n    - processor_count\n    - devices\n    \"\"\"\n    platform = 'FreeBSD'\n    DMESG_BOOT = '/var/run/dmesg.boot'\n\n    def __init__(self):\n        Hardware.__init__(self)\n\n    def populate(self):\n        self.get_cpu_facts()\n        self.get_memory_facts()\n        self.get_dmi_facts()\n        self.get_device_facts()\n        try:\n            self.get_mount_facts()\n        except TimeoutError:\n            pass\n        return self.facts\n\n    def get_cpu_facts(self):\n        self.facts['processor'] = []\n        rc, out, err = module.run_command(\"/sbin/sysctl -n hw.ncpu\")\n        self.facts['processor_count'] = out.strip()\n\n        dmesg_boot = get_file_content(FreeBSDHardware.DMESG_BOOT)\n        if not dmesg_boot:\n            rc, dmesg_boot, err = module.run_command(\"/sbin/dmesg\")\n        for line in dmesg_boot.split('\\n'):\n            if 'CPU:' in line:\n                cpu = re.sub(r'CPU:\\s+', r\"\", line)\n                self.facts['processor'].append(cpu.strip())\n            if 'Logical CPUs per core' in line:\n                self.facts['processor_cores'] = line.split()[4]\n\n\n    def get_memory_facts(self):\n        rc, out, err = module.run_command(\"/sbin/sysctl vm.stats\")\n        for line in out.split('\\n'):\n            data = line.split()\n            if 'vm.stats.vm.v_page_size' in line:\n                pagesize = long(data[1])\n            if 'vm.stats.vm.v_page_count' in line:\n                pagecount = long(data[1])\n            if 'vm.stats.vm.v_free_count' in line:\n                freecount = long(data[1])\n        self.facts['memtotal_mb'] = pagesize * pagecount / 1024 / 1024\n        self.facts['memfree_mb'] = pagesize * freecount / 1024 / 1024\n        # Get swapinfo.  swapinfo output looks like:\n        # Device          1M-blocks     Used    Avail Capacity\n        # /dev/ada0p3        314368        0   314368     0%\n        #\n        rc, out, err = module.run_command(\"/usr/sbin/swapinfo -m\")\n        lines = out.split('\\n')\n        if len(lines[-1]) == 0:\n            lines.pop()\n        data = lines[-1].split()\n        self.facts['swaptotal_mb'] = data[1]\n        self.facts['swapfree_mb'] = data[3]\n\n    @timeout(10)\n    def get_mount_facts(self):\n        self.facts['mounts'] = []\n        fstab = get_file_content('/etc/fstab')\n        if fstab:\n            for line in fstab.split('\\n'):\n                if line.startswith('#') or line.strip() == '':\n                    continue\n                fields = re.sub(r'\\s+',' ',line.rstrip('\\n')).split()\n                self.facts['mounts'].append({'mount': fields[1], 'device': fields[0], 'fstype' : fields[2], 'options': fields[3]})\n\n    def get_device_facts(self):\n        sysdir = '/dev'\n        self.facts['devices'] = {}\n        drives = re.compile('(ada?\\d+|da\\d+|a?cd\\d+)') #TODO: rc, disks, err = module.run_command(\"/sbin/sysctl kern.disks\")\n        slices = re.compile('(ada?\\d+s\\d+\\w*|da\\d+s\\d+\\w*)')\n        if os.path.isdir(sysdir):\n            dirlist = sorted(os.listdir(sysdir))\n            for device in dirlist:\n                d = drives.match(device)\n                if d:\n                    self.facts['devices'][d.group(1)] = []\n                s = slices.match(device)\n                if s:\n                    self.facts['devices'][d.group(1)].append(s.group(1))\n\n    def get_dmi_facts(self):\n        ''' learn dmi facts from system\n\n        Use dmidecode executable if available'''\n\n        # Fall back to using dmidecode, if available\n        dmi_bin = module.get_bin_path('dmidecode')\n        DMI_DICT = dict(\n            bios_date='bios-release-date',\n            bios_version='bios-version',\n            form_factor='chassis-type',\n            product_name='system-product-name',\n            product_serial='system-serial-number',\n            product_uuid='system-uuid',\n            product_version='system-version',\n            system_vendor='system-manufacturer'\n        )\n        for (k, v) in DMI_DICT.items():\n            if dmi_bin is not None:\n                (rc, out, err) = module.run_command('%s -s %s' % (dmi_bin, v))\n                if rc == 0:\n                    # Strip out commented lines (specific dmidecode output)\n                    self.facts[k] = ''.join([ line for line in out.split('\\n') if not line.startswith('#') ])\n                    try:\n                        json.dumps(self.facts[k])\n                    except UnicodeDecodeError:\n                        self.facts[k] = 'NA'\n                else:\n                    self.facts[k] = 'NA'\n            else:\n                self.facts[k] = 'NA'\n\n\nclass NetBSDHardware(Hardware):\n    \"\"\"\n    NetBSD-specific subclass of Hardware.  Defines memory and CPU facts:\n    - memfree_mb\n    - memtotal_mb\n    - swapfree_mb\n    - swaptotal_mb\n    - processor (a list)\n    - processor_cores\n    - processor_count\n    - devices\n    \"\"\"\n    platform = 'NetBSD'\n    MEMORY_FACTS = ['MemTotal', 'SwapTotal', 'MemFree', 'SwapFree']\n\n    def __init__(self):\n        Hardware.__init__(self)\n\n    def populate(self):\n        self.get_cpu_facts()\n        self.get_memory_facts()\n        try:\n            self.get_mount_facts()\n        except TimeoutError:\n            pass\n        return self.facts\n\n    def get_cpu_facts(self):\n\n        i = 0\n        physid = 0\n        sockets = {}\n        if not os.access(\"/proc/cpuinfo\", os.R_OK):\n            return\n        self.facts['processor'] = []\n        for line in open(\"/proc/cpuinfo\").readlines():\n            data = line.split(\":\", 1)\n            key = data[0].strip()\n            # model name is for Intel arch, Processor (mind the uppercase P)\n            # works for some ARM devices, like the Sheevaplug.\n            if key == 'model name' or key == 'Processor':\n                if 'processor' not in self.facts:\n                    self.facts['processor'] = []\n                self.facts['processor'].append(data[1].strip())\n                i += 1\n            elif key == 'physical id':\n                physid = data[1].strip()\n                if physid not in sockets:\n                    sockets[physid] = 1\n            elif key == 'cpu cores':\n                sockets[physid] = int(data[1].strip())\n        if len(sockets) > 0:\n            self.facts['processor_count'] = len(sockets)\n            self.facts['processor_cores'] = reduce(lambda x, y: x + y, sockets.values())\n        else:\n            self.facts['processor_count'] = i\n            self.facts['processor_cores'] = 'NA'\n\n    def get_memory_facts(self):\n        if not os.access(\"/proc/meminfo\", os.R_OK):\n            return\n        for line in open(\"/proc/meminfo\").readlines():\n            data = line.split(\":\", 1)\n            key = data[0]\n            if key in NetBSDHardware.MEMORY_FACTS:\n                val = data[1].strip().split(' ')[0]\n                self.facts[\"%s_mb\" % key.lower()] = long(val) / 1024\n\n    @timeout(10)\n    def get_mount_facts(self):\n        self.facts['mounts'] = []\n        fstab = get_file_content('/etc/fstab')\n        if fstab:\n            for line in fstab.split('\\n'):\n                if line.startswith('#') or line.strip() == '':\n                    continue\n                fields = re.sub(r'\\s+',' ',line.rstrip('\\n')).split()\n                self.facts['mounts'].append({'mount': fields[1], 'device': fields[0], 'fstype' : fields[2], 'options': fields[3]})\n\nclass AIX(Hardware):\n    \"\"\"\n    AIX-specific subclass of Hardware.  Defines memory and CPU facts:\n    - memfree_mb\n    - memtotal_mb\n    - swapfree_mb\n    - swaptotal_mb\n    - processor (a list)\n    - processor_cores\n    - processor_count\n    \"\"\"\n    platform = 'AIX'\n\n    def __init__(self):\n        Hardware.__init__(self)\n\n    def populate(self):\n        self.get_cpu_facts()\n        self.get_memory_facts()\n        self.get_dmi_facts()\n        return self.facts\n\n    def get_cpu_facts(self):\n        self.facts['processor'] = []\n\n\n        rc, out, err = module.run_command(\"/usr/sbin/lsdev -Cc processor\")\n        if out:\n            i = 0\n            for line in out.split('\\n'):\n\n                if 'Available' in line:\n                    if i == 0:\n                        data = line.split(' ')\n                        cpudev = data[0]\n\n                    i += 1\n            self.facts['processor_count'] = int(i)\n\n            rc, out, err = module.run_command(\"/usr/sbin/lsattr -El \" + cpudev + \" -a type\")\n\n            data = out.split(' ')\n            self.facts['processor'] = data[1]\n\n            rc, out, err = module.run_command(\"/usr/sbin/lsattr -El \" + cpudev + \" -a smt_threads\")\n\n            data = out.split(' ')\n            self.facts['processor_cores'] = int(data[1])\n\n    def get_memory_facts(self):\n        pagesize = 4096\n        rc, out, err = module.run_command(\"/usr/bin/vmstat -v\")\n        for line in out.split('\\n'):\n            data = line.split()\n            if 'memory pages' in line:\n                pagecount = long(data[0])\n            if 'free pages' in line:\n                freecount = long(data[0])\n        self.facts['memtotal_mb'] = pagesize * pagecount / 1024 / 1024\n        self.facts['memfree_mb'] = pagesize * freecount / 1024 / 1024\n        # Get swapinfo.  swapinfo output looks like:\n        # Device          1M-blocks     Used    Avail Capacity\n        # /dev/ada0p3        314368        0   314368     0%\n        #\n        rc, out, err = module.run_command(\"/usr/sbin/lsps -s\")\n        if out:\n            lines = out.split('\\n')\n            data = lines[1].split()\n            swaptotal_mb = long(data[0].rstrip('MB'))\n            percused = int(data[1].rstrip('%'))\n            self.facts['swaptotal_mb'] = swaptotal_mb\n            self.facts['swapfree_mb'] = long(swaptotal_mb * ( 100 - percused ) / 100)\n\n    def get_dmi_facts(self):\n        rc, out, err = module.run_command(\"/usr/sbin/lsattr -El sys0 -a fwversion\")\n        data = out.split()\n        self.facts['firmware_version'] = data[1].strip('IBM,')\n\nclass HPUX(Hardware):\n    \"\"\"\n    HP-UX-specifig subclass of Hardware. Defines memory and CPU facts:\n    - memfree_mb\n    - memtotal_mb\n    - swapfree_mb\n    - swaptotal_mb\n    - processor\n    - processor_cores\n    - processor_count\n    - model\n    - firmware\n    \"\"\"\n\n    platform = 'HP-UX'\n\n    def __init__(self):\n        Hardware.__init__(self)\n\n    def populate(self):\n        self.get_cpu_facts()\n        self.get_memory_facts()\n        self.get_hw_facts()\n        return self.facts\n\n    def get_cpu_facts(self):\n        if self.facts['architecture'] == '9000/800':\n            rc, out, err = module.run_command(\"ioscan -FkCprocessor | wc -l\", use_unsafe_shell=True)\n            self.facts['processor_count'] = int(out.strip())\n        #Working with machinfo mess\n        elif self.facts['architecture'] == 'ia64':\n            if self.facts['distribution_version'] == \"B.11.23\":\n                rc, out, err = module.run_command(\"/usr/contrib/bin/machinfo | grep 'Number of CPUs'\", use_unsafe_shell=True)\n                self.facts['processor_count'] = int(out.strip().split('=')[1])\n                rc, out, err = module.run_command(\"/usr/contrib/bin/machinfo | grep 'processor family'\", use_unsafe_shell=True)\n                self.facts['processor'] = re.search('.*(Intel.*)', out).groups()[0].strip()\n                rc, out, err = module.run_command(\"ioscan -FkCprocessor | wc -l\", use_unsafe_shell=True)\n                self.facts['processor_cores'] = int(out.strip())\n            if self.facts['distribution_version'] == \"B.11.31\":\n                #if machinfo return cores strings release B.11.31 > 1204\n                rc, out, err = module.run_command(\"/usr/contrib/bin/machinfo | grep core | wc -l\", use_unsafe_shell=True)\n                if out.strip()== '0':\n                    rc, out, err = module.run_command(\"/usr/contrib/bin/machinfo | grep Intel\", use_unsafe_shell=True)\n                    self.facts['processor_count'] = int(out.strip().split(\" \")[0])\n                    #If hyperthreading is active divide cores by 2\n                    rc, out, err = module.run_command(\"/usr/sbin/psrset | grep LCPU\", use_unsafe_shell=True)\n                    data = re.sub(' +',' ',out).strip().split(' ')\n                    if len(data) == 1:\n                        hyperthreading = 'OFF'\n                    else:\n                        hyperthreading = data[1]\n                    rc, out, err = module.run_command(\"/usr/contrib/bin/machinfo | grep logical\", use_unsafe_shell=True)\n                    data = out.strip().split(\" \")\n                    if hyperthreading == 'ON':\n                        self.facts['processor_cores'] = int(data[0])/2\n                    else:\n                        if len(data) == 1:\n                            self.facts['processor_cores'] = self.facts['processor_count']\n                        else:\n                            self.facts['processor_cores'] = int(data[0])\n                    rc, out, err = module.run_command(\"/usr/contrib/bin/machinfo | grep Intel |cut -d' ' -f4-\", use_unsafe_shell=True)\n                    self.facts['processor'] = out.strip()\n                else:\n                    rc, out, err = module.run_command(\"/usr/contrib/bin/machinfo | egrep 'socket[s]?$' | tail -1\", use_unsafe_shell=True)\n                    self.facts['processor_count'] = int(out.strip().split(\" \")[0])\n                    rc, out, err = module.run_command(\"/usr/contrib/bin/machinfo | grep -e '[0-9] core' | tail -1\", use_unsafe_shell=True)\n                    self.facts['processor_cores'] = int(out.strip().split(\" \")[0])\n                    rc, out, err = module.run_command(\"/usr/contrib/bin/machinfo | grep Intel\", use_unsafe_shell=True)\n                    self.facts['processor'] = out.strip()\n\n    def get_memory_facts(self):\n        pagesize = 4096\n        rc, out, err = module.run_command(\"/usr/bin/vmstat | tail -1\", use_unsafe_shell=True)\n        data = int(re.sub(' +',' ',out).split(' ')[5].strip())\n        self.facts['memfree_mb'] = pagesize * data / 1024 / 1024\n        if self.facts['architecture'] == '9000/800':\n            try:\n                rc, out, err = module.run_command(\"grep Physical /var/adm/syslog/syslog.log\")\n                data = re.search('.*Physical: ([0-9]*) Kbytes.*',out).groups()[0].strip()\n                self.facts['memtotal_mb'] = int(data) / 1024\n            except AttributeError:\n                #For systems where memory details aren't sent to syslog or the log has rotated, use parsed\n                #adb output. Unfortunatley /dev/kmem doesn't have world-read, so this only works as root.\n                if os.access(\"/dev/kmem\", os.R_OK):\n                    rc, out, err = module.run_command(\"echo 'phys_mem_pages/D' | adb -k /stand/vmunix /dev/kmem | tail -1 | awk '{print $2}'\", use_unsafe_shell=True)\n                    if not err:\n                      data = out\n                      self.facts['memtotal_mb'] = int(data) / 256\n        else:\n            rc, out, err = module.run_command(\"/usr/contrib/bin/machinfo | grep Memory\", use_unsafe_shell=True)\n            data = re.search('Memory[\\ :=]*([0-9]*).*MB.*',out).groups()[0].strip()\n            self.facts['memtotal_mb'] = int(data)\n        rc, out, err = module.run_command(\"/usr/sbin/swapinfo -m -d -f -q\")\n        self.facts['swaptotal_mb'] = int(out.strip())\n        rc, out, err = module.run_command(\"/usr/sbin/swapinfo -m -d -f | egrep '^dev|^fs'\", use_unsafe_shell=True)\n        swap = 0\n        for line in out.strip().split('\\n'):\n            swap += int(re.sub(' +',' ',line).split(' ')[3].strip())\n        self.facts['swapfree_mb'] = swap\n\n    def get_hw_facts(self):\n        rc, out, err = module.run_command(\"model\")\n        self.facts['model'] = out.strip()\n        if self.facts['architecture'] == 'ia64':\n            separator = ':'\n            if self.facts['distribution_version'] == \"B.11.23\":\n                separator = '='\n            rc, out, err = module.run_command(\"/usr/contrib/bin/machinfo |grep -i 'Firmware revision' | grep -v BMC\", use_unsafe_shell=True)\n            self.facts['firmware_version'] = out.split(separator)[1].strip()\n\n\nclass Darwin(Hardware):\n    \"\"\"\n    Darwin-specific subclass of Hardware.  Defines memory and CPU facts:\n    - processor\n    - processor_cores\n    - memtotal_mb\n    - memfree_mb\n    - model\n    - osversion\n    - osrevision\n    \"\"\"\n    platform = 'Darwin'\n\n    def __init__(self):\n        Hardware.__init__(self)\n\n    def populate(self):\n        self.sysctl = self.get_sysctl()\n        self.get_mac_facts()\n        self.get_cpu_facts()\n        self.get_memory_facts()\n        return self.facts\n\n    def get_sysctl(self):\n        rc, out, err = module.run_command([\"/usr/sbin/sysctl\", \"hw\", \"machdep\", \"kern\"])\n        if rc != 0:\n            return dict()\n        sysctl = dict()\n        for line in out.splitlines():\n            if line.rstrip(\"\\n\"):\n                (key, value) = re.split(' = |: ', line, maxsplit=1)\n                sysctl[key] = value.strip()\n        return sysctl\n\n    def get_system_profile(self):\n        rc, out, err = module.run_command([\"/usr/sbin/system_profiler\", \"SPHardwareDataType\"])\n        if rc != 0:\n            return dict()\n        system_profile = dict()\n        for line in out.splitlines():\n            if ': ' in line:\n                (key, value) = line.split(': ', 1)\n                system_profile[key.strip()] = ' '.join(value.strip().split())\n        return system_profile\n\n    def get_mac_facts(self):\n        rc, out, err = module.run_command(\"sysctl hw.model\")\n        if rc == 0:\n            self.facts['model'] = out.splitlines()[-1].split()[1]\n        self.facts['osversion'] = self.sysctl['kern.osversion']\n        self.facts['osrevision'] = self.sysctl['kern.osrevision']\n\n    def get_cpu_facts(self):\n        if 'machdep.cpu.brand_string' in self.sysctl: # Intel\n            self.facts['processor'] = self.sysctl['machdep.cpu.brand_string']\n            self.facts['processor_cores'] = self.sysctl['machdep.cpu.core_count']\n        else: # PowerPC\n            system_profile = self.get_system_profile()\n            self.facts['processor'] = '%s @ %s' % (system_profile['Processor Name'], system_profile['Processor Speed'])\n            self.facts['processor_cores'] = self.sysctl['hw.physicalcpu']\n\n    def get_memory_facts(self):\n        self.facts['memtotal_mb'] = long(self.sysctl['hw.memsize']) / 1024 / 1024\n\n        rc, out, err = module.run_command(\"sysctl hw.usermem\")\n        if rc == 0:\n            self.facts['memfree_mb'] = long(out.splitlines()[-1].split()[1]) / 1024 / 1024\n\nclass Network(Facts):\n    \"\"\"\n    This is a generic Network subclass of Facts.  This should be further\n    subclassed to implement per platform.  If you subclass this,\n    you must define:\n    - interfaces (a list of interface names)\n    - interface_<name> dictionary of ipv4, ipv6, and mac address information.\n\n    All subclasses MUST define platform.\n    \"\"\"\n    platform = 'Generic'\n\n    IPV6_SCOPE = { '0' : 'global',\n                   '10' : 'host',\n                   '20' : 'link',\n                   '40' : 'admin',\n                   '50' : 'site',\n                   '80' : 'organization' }\n\n    def __new__(cls, *arguments, **keyword):\n        subclass = cls\n        for sc in Network.__subclasses__():\n            if sc.platform == platform.system():\n                subclass = sc\n        return super(cls, subclass).__new__(subclass, *arguments, **keyword)\n\n    def __init__(self, module):\n        self.module = module\n        Facts.__init__(self)\n\n    def populate(self):\n        return self.facts\n\nclass LinuxNetwork(Network):\n    \"\"\"\n    This is a Linux-specific subclass of Network.  It defines\n    - interfaces (a list of interface names)\n    - interface_<name> dictionary of ipv4, ipv6, and mac address information.\n    - all_ipv4_addresses and all_ipv6_addresses: lists of all configured addresses.\n    - ipv4_address and ipv6_address: the first non-local address for each family.\n    \"\"\"\n    platform = 'Linux'\n\n    def __init__(self, module):\n        Network.__init__(self, module)\n\n    def populate(self):\n        ip_path = self.module.get_bin_path('ip')\n        if ip_path is None:\n            return self.facts\n        default_ipv4, default_ipv6 = self.get_default_interfaces(ip_path)\n        interfaces, ips = self.get_interfaces_info(ip_path, default_ipv4, default_ipv6)\n        self.facts['interfaces'] = interfaces.keys()\n        for iface in interfaces:\n            self.facts[iface] = interfaces[iface]\n        self.facts['default_ipv4'] = default_ipv4\n        self.facts['default_ipv6'] = default_ipv6\n        self.facts['all_ipv4_addresses'] = ips['all_ipv4_addresses']\n        self.facts['all_ipv6_addresses'] = ips['all_ipv6_addresses']\n        return self.facts\n\n    def get_default_interfaces(self, ip_path):\n        # Use the commands:\n        #     ip -4 route get 8.8.8.8                     -> Google public DNS\n        #     ip -6 route get 2404:6800:400a:800::1012    -> ipv6.google.com\n        # to find out the default outgoing interface, address, and gateway\n        command = dict(\n            v4 = [ip_path, '-4', 'route', 'get', '8.8.8.8'],\n            v6 = [ip_path, '-6', 'route', 'get', '2404:6800:400a:800::1012']\n        )\n        interface = dict(v4 = {}, v6 = {})\n        for v in 'v4', 'v6':\n            if v == 'v6' and self.facts['os_family'] == 'RedHat' \\\n                and self.facts['distribution_version'].startswith('4.'):\n                continue\n            if v == 'v6' and not socket.has_ipv6:\n                continue\n            rc, out, err = module.run_command(command[v])\n            if not out:\n                # v6 routing may result in\n                #   RTNETLINK answers: Invalid argument\n                continue\n            words = out.split('\\n')[0].split()\n            # A valid output starts with the queried address on the first line\n            if len(words) > 0 and words[0] == command[v][-1]:\n                for i in range(len(words) - 1):\n                    if words[i] == 'dev':\n                        interface[v]['interface'] = words[i+1]\n                    elif words[i] == 'src':\n                        interface[v]['address'] = words[i+1]\n                    elif words[i] == 'via' and words[i+1] != command[v][-1]:\n                        interface[v]['gateway'] = words[i+1]\n        return interface['v4'], interface['v6']\n\n    def get_interfaces_info(self, ip_path, default_ipv4, default_ipv6):\n        interfaces = {}\n        ips = dict(\n            all_ipv4_addresses = [],\n            all_ipv6_addresses = [],\n        )\n\n        for path in glob.glob('/sys/class/net/*'):\n            if not os.path.isdir(path):\n                continue\n            device = os.path.basename(path)\n            interfaces[device] = { 'device': device }\n            if os.path.exists(os.path.join(path, 'address')):\n                macaddress = open(os.path.join(path, 'address')).read().strip()\n                if macaddress and macaddress != '00:00:00:00:00:00':\n                    interfaces[device]['macaddress'] = macaddress\n            if os.path.exists(os.path.join(path, 'mtu')):\n                interfaces[device]['mtu'] = int(open(os.path.join(path, 'mtu')).read().strip())\n            if os.path.exists(os.path.join(path, 'operstate')):\n                interfaces[device]['active'] = open(os.path.join(path, 'operstate')).read().strip() != 'down'\n#            if os.path.exists(os.path.join(path, 'carrier')):\n#                interfaces[device]['link'] = open(os.path.join(path, 'carrier')).read().strip() == '1'\n            if os.path.exists(os.path.join(path, 'device','driver', 'module')):\n                interfaces[device]['module'] = os.path.basename(os.path.realpath(os.path.join(path, 'device', 'driver', 'module')))\n            if os.path.exists(os.path.join(path, 'type')):\n                type = open(os.path.join(path, 'type')).read().strip()\n                if type == '1':\n                    interfaces[device]['type'] = 'ether'\n                elif type == '512':\n                    interfaces[device]['type'] = 'ppp'\n                elif type == '772':\n                    interfaces[device]['type'] = 'loopback'\n            if os.path.exists(os.path.join(path, 'bridge')):\n                interfaces[device]['type'] = 'bridge'\n                interfaces[device]['interfaces'] = [ os.path.basename(b) for b in glob.glob(os.path.join(path, 'brif', '*')) ]\n                if os.path.exists(os.path.join(path, 'bridge', 'bridge_id')):\n                    interfaces[device]['id'] = open(os.path.join(path, 'bridge', 'bridge_id')).read().strip()\n                if os.path.exists(os.path.join(path, 'bridge', 'stp_state')):\n                    interfaces[device]['stp'] = open(os.path.join(path, 'bridge', 'stp_state')).read().strip() == '1'\n            if os.path.exists(os.path.join(path, 'bonding')):\n                interfaces[device]['type'] = 'bonding'\n                interfaces[device]['slaves'] = open(os.path.join(path, 'bonding', 'slaves')).read().split()\n                interfaces[device]['mode'] = open(os.path.join(path, 'bonding', 'mode')).read().split()[0]\n                interfaces[device]['miimon'] = open(os.path.join(path, 'bonding', 'miimon')).read().split()[0]\n                interfaces[device]['lacp_rate'] = open(os.path.join(path, 'bonding', 'lacp_rate')).read().split()[0]\n                primary = open(os.path.join(path, 'bonding', 'primary')).read()\n                if primary:\n                    interfaces[device]['primary'] = primary\n                    path = os.path.join(path, 'bonding', 'all_slaves_active')\n                    if os.path.exists(path):\n                        interfaces[device]['all_slaves_active'] = open(path).read() == '1'\n\n            # Check whether an interface is in promiscuous mode\n            if os.path.exists(os.path.join(path,'flags')):\n                promisc_mode = False\n                # The second byte indicates whether the interface is in promiscuous mode.\n                # 1 = promisc\n                # 0 = no promisc\n                data = int(open(os.path.join(path, 'flags')).read().strip(),16)\n                promisc_mode = (data & 0x0100 > 0)\n                interfaces[device]['promisc'] = promisc_mode\n\n            def parse_ip_output(output, secondary=False):\n                for line in output.split('\\n'):\n                    if not line:\n                        continue\n                    words = line.split()\n                    if words[0] == 'inet':\n                        if '/' in words[1]:\n                            address, netmask_length = words[1].split('/')\n                        else:\n                            # pointopoint interfaces do not have a prefix\n                            address = words[1]\n                            netmask_length = \"32\"\n                        address_bin = struct.unpack('!L', socket.inet_aton(address))[0]\n                        netmask_bin = (1<<32) - (1<<32>>int(netmask_length))\n                        netmask = socket.inet_ntoa(struct.pack('!L', netmask_bin))\n                        network = socket.inet_ntoa(struct.pack('!L', address_bin & netmask_bin))\n                        iface = words[-1]\n                        if iface != device:\n                            interfaces[iface] = {}\n                        if not secondary and \"ipv4\" not in interfaces[iface]:\n                            interfaces[iface]['ipv4'] = {'address': address,\n                                                         'netmask': netmask,\n                                                         'network': network}\n                        else:\n                            if \"ipv4_secondaries\" not in interfaces[iface]:\n                                interfaces[iface][\"ipv4_secondaries\"] = []\n                            interfaces[iface][\"ipv4_secondaries\"].append({\n                                'address': address,\n                                'netmask': netmask,\n                                'network': network,\n                            })\n\n                        # add this secondary IP to the main device\n                        if secondary:\n                            if \"ipv4_secondaries\" not in interfaces[device]:\n                                interfaces[device][\"ipv4_secondaries\"] = []\n                            interfaces[device][\"ipv4_secondaries\"].append({\n                                'address': address,\n                                'netmask': netmask,\n                                'network': network,\n                            })\n\n                        # If this is the default address, update default_ipv4\n                        if 'address' in default_ipv4 and default_ipv4['address'] == address:\n                            default_ipv4['netmask'] = netmask\n                            default_ipv4['network'] = network\n                            default_ipv4['macaddress'] = macaddress\n                            default_ipv4['mtu'] = interfaces[device]['mtu']\n                            default_ipv4['type'] = interfaces[device].get(\"type\", \"unknown\")\n                            default_ipv4['alias'] = words[-1]\n                        if not address.startswith('127.'):\n                            ips['all_ipv4_addresses'].append(address)\n                    elif words[0] == 'inet6':\n                        address, prefix = words[1].split('/')\n                        scope = words[3]\n                        if 'ipv6' not in interfaces[device]:\n                            interfaces[device]['ipv6'] = []\n                        interfaces[device]['ipv6'].append({\n                            'address' : address,\n                            'prefix'  : prefix,\n                            'scope'   : scope\n                        })\n                        # If this is the default address, update default_ipv6\n                        if 'address' in default_ipv6 and default_ipv6['address'] == address:\n                            default_ipv6['prefix']     = prefix\n                            default_ipv6['scope']      = scope\n                            default_ipv6['macaddress'] = macaddress\n                            default_ipv6['mtu']        = interfaces[device]['mtu']\n                            default_ipv6['type']       = interfaces[device].get(\"type\", \"unknown\")\n                        if not address == '::1':\n                            ips['all_ipv6_addresses'].append(address)\n\n            ip_path = module.get_bin_path(\"ip\")\n\n            args = [ip_path, 'addr', 'show', 'primary', device]\n            rc, stdout, stderr = self.module.run_command(args)\n            primary_data = stdout\n\n            args = [ip_path, 'addr', 'show', 'secondary', device]\n            rc, stdout, stderr = self.module.run_command(args)\n            secondary_data = stdout\n\n            parse_ip_output(primary_data)\n            parse_ip_output(secondary_data, secondary=True)\n\n        # replace : by _ in interface name since they are hard to use in template\n        new_interfaces = {}\n        for i in interfaces:\n            if ':' in i:\n                new_interfaces[i.replace(':','_')] = interfaces[i]\n            else:\n                new_interfaces[i] = interfaces[i]\n        return new_interfaces, ips\n\nclass GenericBsdIfconfigNetwork(Network):\n    \"\"\"\n    This is a generic BSD subclass of Network using the ifconfig command.\n    It defines\n    - interfaces (a list of interface names)\n    - interface_<name> dictionary of ipv4, ipv6, and mac address information.\n    - all_ipv4_addresses and all_ipv6_addresses: lists of all configured addresses.\n    It currently does not define\n    - default_ipv4 and default_ipv6\n    - type, mtu and network on interfaces\n    \"\"\"\n    platform = 'Generic_BSD_Ifconfig'\n\n    def __init__(self, module):\n        Network.__init__(self, module)\n\n    def populate(self):\n\n        ifconfig_path = module.get_bin_path('ifconfig')\n\n        if ifconfig_path is None:\n            return self.facts\n        route_path = module.get_bin_path('route')\n\n        if route_path is None:\n            return self.facts\n\n        default_ipv4, default_ipv6 = self.get_default_interfaces(route_path)\n        interfaces, ips = self.get_interfaces_info(ifconfig_path)\n        self.merge_default_interface(default_ipv4, interfaces, 'ipv4')\n        self.merge_default_interface(default_ipv6, interfaces, 'ipv6')\n        self.facts['interfaces'] = interfaces.keys()\n\n        for iface in interfaces:\n            self.facts[iface] = interfaces[iface]\n\n        self.facts['default_ipv4'] = default_ipv4\n        self.facts['default_ipv6'] = default_ipv6\n        self.facts['all_ipv4_addresses'] = ips['all_ipv4_addresses']\n        self.facts['all_ipv6_addresses'] = ips['all_ipv6_addresses']\n\n        return self.facts\n\n    def get_default_interfaces(self, route_path):\n\n        # Use the commands:\n        #     route -n get 8.8.8.8                            -> Google public DNS\n        #     route -n get -inet6 2404:6800:400a:800::1012    -> ipv6.google.com\n        # to find out the default outgoing interface, address, and gateway\n\n        command = dict(\n            v4 = [route_path, '-n', 'get', '8.8.8.8'],\n            v6 = [route_path, '-n', 'get', '-inet6', '2404:6800:400a:800::1012']\n        )\n\n        interface = dict(v4 = {}, v6 = {})\n\n        for v in 'v4', 'v6':\n\n            if v == 'v6' and not socket.has_ipv6:\n                continue\n            rc, out, err = module.run_command(command[v])\n            if not out:\n                # v6 routing may result in\n                #   RTNETLINK answers: Invalid argument\n                continue\n            lines = out.split('\\n')\n            for line in lines:\n                words = line.split()\n                # Collect output from route command\n                if len(words) > 1:\n                    if words[0] == 'interface:':\n                        interface[v]['interface'] = words[1]\n                    if words[0] == 'gateway:':\n                        interface[v]['gateway'] = words[1]\n\n        return interface['v4'], interface['v6']\n\n    def get_interfaces_info(self, ifconfig_path):\n        interfaces = {}\n        current_if = {}\n        ips = dict(\n            all_ipv4_addresses = [],\n            all_ipv6_addresses = [],\n        )\n        # FreeBSD, DragonflyBSD, NetBSD, OpenBSD and OS X all implicitly add '-a'\n        # when running the command 'ifconfig'.\n        # Solaris must explicitly run the command 'ifconfig -a'.\n        rc, out, err = module.run_command([ifconfig_path, '-a'])\n\n        for line in out.split('\\n'):\n\n            if line:\n                words = line.split()\n\n                if words[0] == 'pass':\n                    continue\n                elif re.match('^\\S', line) and len(words) > 3:\n                    current_if = self.parse_interface_line(words)\n                    interfaces[ current_if['device'] ] = current_if\n                elif words[0].startswith('options='):\n                    self.parse_options_line(words, current_if, ips)\n                elif words[0] == 'nd6':\n                    self.parse_nd6_line(words, current_if, ips)\n                elif words[0] == 'ether':\n                    self.parse_ether_line(words, current_if, ips)\n                elif words[0] == 'media:':\n                    self.parse_media_line(words, current_if, ips)\n                elif words[0] == 'status:':\n                    self.parse_status_line(words, current_if, ips)\n                elif words[0] == 'lladdr':\n                    self.parse_lladdr_line(words, current_if, ips)\n                elif words[0] == 'inet':\n                    self.parse_inet_line(words, current_if, ips)\n                elif words[0] == 'inet6':\n                    self.parse_inet6_line(words, current_if, ips)\n                else:\n                    self.parse_unknown_line(words, current_if, ips)\n\n        return interfaces, ips\n\n    def parse_interface_line(self, words):\n        device = words[0][0:-1]\n        current_if = {'device': device, 'ipv4': [], 'ipv6': [], 'type': 'unknown'}\n        current_if['flags']  = self.get_options(words[1])\n        current_if['macaddress'] = 'unknown'    # will be overwritten later\n\n        if len(words) >= 5 : # Newer FreeBSD versions\n            current_if['metric'] = words[3]\n            current_if['mtu'] = words[5]\n        else:\n            current_if['mtu'] = words[3]\n\n        return current_if\n\n    def parse_options_line(self, words, current_if, ips):\n        # Mac has options like this...\n        current_if['options'] = self.get_options(words[0])\n\n    def parse_nd6_line(self, words, current_if, ips):\n        # FreBSD has options like this...\n        current_if['options'] = self.get_options(words[1])\n\n    def parse_ether_line(self, words, current_if, ips):\n        current_if['macaddress'] = words[1]\n\n    def parse_media_line(self, words, current_if, ips):\n        # not sure if this is useful - we also drop information\n        current_if['media'] = words[1]\n        if len(words) > 2:\n            current_if['media_select'] = words[2]\n        if len(words) > 3:\n            current_if['media_type'] = words[3][1:]\n        if len(words) > 4:\n            current_if['media_options'] = self.get_options(words[4])\n\n    def parse_status_line(self, words, current_if, ips):\n        current_if['status'] = words[1]\n\n    def parse_lladdr_line(self, words, current_if, ips):\n        current_if['lladdr'] = words[1]\n\n    def parse_inet_line(self, words, current_if, ips):\n        address = {'address': words[1]}\n        # deal with hex netmask\n        if re.match('([0-9a-f]){8}', words[3]) and len(words[3]) == 8:\n            words[3] = '0x' + words[3]\n        if words[3].startswith('0x'):\n            address['netmask'] = socket.inet_ntoa(struct.pack('!L', int(words[3], base=16)))\n        else:\n            # otherwise assume this is a dotted quad\n            address['netmask'] = words[3]\n        # calculate the network\n        address_bin = struct.unpack('!L', socket.inet_aton(address['address']))[0]\n        netmask_bin = struct.unpack('!L', socket.inet_aton(address['netmask']))[0]\n        address['network'] = socket.inet_ntoa(struct.pack('!L', address_bin & netmask_bin))\n        # broadcast may be given or we need to calculate\n        if len(words) > 5:\n            address['broadcast'] = words[5]\n        else:\n            address['broadcast'] = socket.inet_ntoa(struct.pack('!L', address_bin | (~netmask_bin & 0xffffffff)))\n        # add to our list of addresses\n        if not words[1].startswith('127.'):\n            ips['all_ipv4_addresses'].append(address['address'])\n        current_if['ipv4'].append(address)\n\n    def parse_inet6_line(self, words, current_if, ips):\n        address = {'address': words[1]}\n        if (len(words) >= 4) and (words[2] == 'prefixlen'):\n            address['prefix'] = words[3]\n        if (len(words) >= 6) and (words[4] == 'scopeid'):\n            address['scope'] = words[5]\n        localhost6 = ['::1', '::1/128', 'fe80::1%lo0']\n        if address['address'] not in localhost6:\n            ips['all_ipv6_addresses'].append(address['address'])\n        current_if['ipv6'].append(address)\n\n    def parse_unknown_line(self, words, current_if, ips):\n        # we are going to ignore unknown lines here - this may be\n        # a bad idea - but you can override it in your subclass\n        pass\n\n    def get_options(self, option_string):\n        start = option_string.find('<') + 1\n        end = option_string.rfind('>')\n        if (start > 0) and (end > 0) and (end > start + 1):\n            option_csv = option_string[start:end]\n            return option_csv.split(',')\n        else:\n            return []\n\n    def merge_default_interface(self, defaults, interfaces, ip_type):\n        if not 'interface' in defaults.keys():\n            return\n        if not defaults['interface'] in interfaces:\n            return\n        ifinfo = interfaces[defaults['interface']]\n        # copy all the interface values across except addresses\n        for item in ifinfo.keys():\n            if item != 'ipv4' and item != 'ipv6':\n                defaults[item] = ifinfo[item]\n        if len(ifinfo[ip_type]) > 0:\n            for item in ifinfo[ip_type][0].keys():\n                defaults[item] = ifinfo[ip_type][0][item]\n\nclass DarwinNetwork(GenericBsdIfconfigNetwork, Network):\n    \"\"\"\n    This is the Mac OS X/Darwin Network Class.\n    It uses the GenericBsdIfconfigNetwork unchanged\n    \"\"\"\n    platform = 'Darwin'\n\n    # media line is different to the default FreeBSD one\n    def parse_media_line(self, words, current_if, ips):\n        # not sure if this is useful - we also drop information\n        current_if['media'] = 'Unknown' # Mac does not give us this\n        current_if['media_select'] = words[1]\n        if len(words) > 2:\n            current_if['media_type'] = words[2][1:]\n        if len(words) > 3:\n            current_if['media_options'] = self.get_options(words[3])\n\n\nclass FreeBSDNetwork(GenericBsdIfconfigNetwork, Network):\n    \"\"\"\n    This is the FreeBSD Network Class.\n    It uses the GenericBsdIfconfigNetwork unchanged.\n    \"\"\"\n    platform = 'FreeBSD'\n\nclass AIXNetwork(GenericBsdIfconfigNetwork, Network):\n    \"\"\"\n    This is the AIX Network Class.\n    It uses the GenericBsdIfconfigNetwork unchanged.\n    \"\"\"\n    platform = 'AIX'\n\n    # AIX 'ifconfig -a' does not have three words in the interface line\n    def get_interfaces_info(self, ifconfig_path):\n        interfaces = {}\n        current_if = {}\n        ips = dict(\n            all_ipv4_addresses = [],\n            all_ipv6_addresses = [],\n        )\n        rc, out, err = module.run_command([ifconfig_path, '-a'])\n\n        for line in out.split('\\n'):\n\n            if line:\n                words = line.split()\n\n\t\t# only this condition differs from GenericBsdIfconfigNetwork\n                if re.match('^\\w*\\d*:', line):\n                    current_if = self.parse_interface_line(words)\n                    interfaces[ current_if['device'] ] = current_if\n                elif words[0].startswith('options='):\n                    self.parse_options_line(words, current_if, ips)\n                elif words[0] == 'nd6':\n                    self.parse_nd6_line(words, current_if, ips)\n                elif words[0] == 'ether':\n                    self.parse_ether_line(words, current_if, ips)\n                elif words[0] == 'media:':\n                    self.parse_media_line(words, current_if, ips)\n                elif words[0] == 'status:':\n                    self.parse_status_line(words, current_if, ips)\n                elif words[0] == 'lladdr':\n                    self.parse_lladdr_line(words, current_if, ips)\n                elif words[0] == 'inet':\n                    self.parse_inet_line(words, current_if, ips)\n                elif words[0] == 'inet6':\n                    self.parse_inet6_line(words, current_if, ips)\n                else:\n                    self.parse_unknown_line(words, current_if, ips)\n\n        return interfaces, ips\n\n    # AIX 'ifconfig -a' does not inform about MTU, so remove current_if['mtu'] here\n    def parse_interface_line(self, words):\n        device = words[0][0:-1]\n        current_if = {'device': device, 'ipv4': [], 'ipv6': [], 'type': 'unknown'}\n        current_if['flags'] = self.get_options(words[1])\n        current_if['macaddress'] = 'unknown'    # will be overwritten later\n        return current_if\n\nclass OpenBSDNetwork(GenericBsdIfconfigNetwork, Network):\n    \"\"\"\n    This is the OpenBSD Network Class.\n    It uses the GenericBsdIfconfigNetwork.\n    \"\"\"\n    platform = 'OpenBSD'\n\n    # Return macaddress instead of lladdr\n    def parse_lladdr_line(self, words, current_if, ips):\n        current_if['macaddress'] = words[1]\n\nclass SunOSNetwork(GenericBsdIfconfigNetwork, Network):\n    \"\"\"\n    This is the SunOS Network Class.\n    It uses the GenericBsdIfconfigNetwork.\n\n    Solaris can have different FLAGS and MTU for IPv4 and IPv6 on the same interface\n    so these facts have been moved inside the 'ipv4' and 'ipv6' lists.\n    \"\"\"\n    platform = 'SunOS'\n\n    # Solaris 'ifconfig -a' will print interfaces twice, once for IPv4 and again for IPv6.\n    # MTU and FLAGS also may differ between IPv4 and IPv6 on the same interface.\n    # 'parse_interface_line()' checks for previously seen interfaces before defining\n    # 'current_if' so that IPv6 facts don't clobber IPv4 facts (or vice versa).\n    def get_interfaces_info(self, ifconfig_path):\n        interfaces = {}\n        current_if = {}\n        ips = dict(\n            all_ipv4_addresses = [],\n            all_ipv6_addresses = [],\n        )\n        rc, out, err = module.run_command([ifconfig_path, '-a'])\n\n        for line in out.split('\\n'):\n\n            if line:\n                words = line.split()\n\n                if re.match('^\\S', line) and len(words) > 3:\n                    current_if = self.parse_interface_line(words, current_if, interfaces)\n                    interfaces[ current_if['device'] ] = current_if\n                elif words[0].startswith('options='):\n                    self.parse_options_line(words, current_if, ips)\n                elif words[0] == 'nd6':\n                    self.parse_nd6_line(words, current_if, ips)\n                elif words[0] == 'ether':\n                    self.parse_ether_line(words, current_if, ips)\n                elif words[0] == 'media:':\n                    self.parse_media_line(words, current_if, ips)\n                elif words[0] == 'status:':\n                    self.parse_status_line(words, current_if, ips)\n                elif words[0] == 'lladdr':\n                    self.parse_lladdr_line(words, current_if, ips)\n                elif words[0] == 'inet':\n                    self.parse_inet_line(words, current_if, ips)\n                elif words[0] == 'inet6':\n                    self.parse_inet6_line(words, current_if, ips)\n                else:\n                    self.parse_unknown_line(words, current_if, ips)\n\n        # 'parse_interface_line' and 'parse_inet*_line' leave two dicts in the\n        # ipv4/ipv6 lists which is ugly and hard to read.\n        # This quick hack merges the dictionaries. Purely cosmetic.\n        for iface in interfaces:\n            for v in 'ipv4', 'ipv6':\n                combined_facts = {}\n                for facts in interfaces[iface][v]:\n                    combined_facts.update(facts)\n                if len(combined_facts.keys()) > 0:\n                    interfaces[iface][v] = [combined_facts]\n\n        return interfaces, ips\n\n    def parse_interface_line(self, words, current_if, interfaces):\n        device = words[0][0:-1]\n        if device not in interfaces.keys():\n            current_if = {'device': device, 'ipv4': [], 'ipv6': [], 'type': 'unknown'}\n        else:\n            current_if = interfaces[device]\n        flags = self.get_options(words[1])\n        v = 'ipv4'\n        if 'IPv6' in flags:\n            v = 'ipv6'\n        current_if[v].append({'flags': flags, 'mtu': words[3]})\n        current_if['macaddress'] = 'unknown'    # will be overwritten later\n        return current_if\n\n    # Solaris displays single digit octets in MAC addresses e.g. 0:1:2:d:e:f\n    # Add leading zero to each octet where needed.\n    def parse_ether_line(self, words, current_if, ips):\n        macaddress = ''\n        for octet in words[1].split(':'):\n            octet = ('0' + octet)[-2:None]\n            macaddress += (octet + ':')\n        current_if['macaddress'] = macaddress[0:-1]\n\nclass Virtual(Facts):\n    \"\"\"\n    This is a generic Virtual subclass of Facts.  This should be further\n    subclassed to implement per platform.  If you subclass this,\n    you should define:\n    - virtualization_type\n    - virtualization_role\n    - container (e.g. solaris zones, freebsd jails, linux containers)\n\n    All subclasses MUST define platform.\n    \"\"\"\n\n    def __new__(cls, *arguments, **keyword):\n        subclass = cls\n        for sc in Virtual.__subclasses__():\n            if sc.platform == platform.system():\n                subclass = sc\n        return super(cls, subclass).__new__(subclass, *arguments, **keyword)\n\n    def __init__(self):\n        Facts.__init__(self)\n\n    def populate(self):\n        return self.facts\n\nclass LinuxVirtual(Virtual):\n    \"\"\"\n    This is a Linux-specific subclass of Virtual.  It defines\n    - virtualization_type\n    - virtualization_role\n    \"\"\"\n    platform = 'Linux'\n\n    def __init__(self):\n        Virtual.__init__(self)\n\n    def populate(self):\n        self.get_virtual_facts()\n        return self.facts\n\n    # For more information, check: http://people.redhat.com/~rjones/virt-what/\n    def get_virtual_facts(self):\n        if os.path.exists(\"/proc/xen\"):\n            self.facts['virtualization_type'] = 'xen'\n            self.facts['virtualization_role'] = 'guest'\n            try:\n                for line in open('/proc/xen/capabilities'):\n                    if \"control_d\" in line:\n                        self.facts['virtualization_role'] = 'host'\n            except IOError:\n                pass\n            return\n\n        if os.path.exists('/proc/vz'):\n            self.facts['virtualization_type'] = 'openvz'\n            if os.path.exists('/proc/bc'):\n                self.facts['virtualization_role'] = 'host'\n            else:\n                self.facts['virtualization_role'] = 'guest'\n            return\n\n        if os.path.exists('/proc/1/cgroup'):\n            for line in open('/proc/1/cgroup').readlines():\n                if re.search('/lxc/', line):\n                    self.facts['virtualization_type'] = 'lxc'\n                    self.facts['virtualization_role'] = 'guest'\n                    return\n\n        product_name = get_file_content('/sys/devices/virtual/dmi/id/product_name')\n\n        if product_name in ['KVM', 'Bochs']:\n            self.facts['virtualization_type'] = 'kvm'\n            self.facts['virtualization_role'] = 'guest'\n            return\n\n        if product_name == 'RHEV Hypervisor':\n            self.facts['virtualization_type'] = 'RHEV'\n            self.facts['virtualization_role'] = 'guest'\n            return\n\n        if product_name == 'VMware Virtual Platform':\n            self.facts['virtualization_type'] = 'VMware'\n            self.facts['virtualization_role'] = 'guest'\n            return\n\n        bios_vendor = get_file_content('/sys/devices/virtual/dmi/id/bios_vendor')\n\n        if bios_vendor == 'Xen':\n            self.facts['virtualization_type'] = 'xen'\n            self.facts['virtualization_role'] = 'guest'\n            return\n\n        if bios_vendor == 'innotek GmbH':\n            self.facts['virtualization_type'] = 'virtualbox'\n            self.facts['virtualization_role'] = 'guest'\n            return\n\n        sys_vendor = get_file_content('/sys/devices/virtual/dmi/id/sys_vendor')\n\n        # FIXME: This does also match hyperv\n        if sys_vendor == 'Microsoft Corporation':\n            self.facts['virtualization_type'] = 'VirtualPC'\n            self.facts['virtualization_role'] = 'guest'\n            return\n\n        if sys_vendor == 'Parallels Software International Inc.':\n            self.facts['virtualization_type'] = 'parallels'\n            self.facts['virtualization_role'] = 'guest'\n            return\n\n        if os.path.exists('/proc/self/status'):\n            for line in open('/proc/self/status').readlines():\n                if re.match('^VxID: \\d+', line):\n                    self.facts['virtualization_type'] = 'linux_vserver'\n                    if re.match('^VxID: 0', line):\n                        self.facts['virtualization_role'] = 'host'\n                    else:\n                        self.facts['virtualization_role'] = 'guest'\n                    return\n\n        if os.path.exists('/proc/cpuinfo'):\n            for line in open('/proc/cpuinfo').readlines():\n                if re.match('^model name.*QEMU Virtual CPU', line):\n                    self.facts['virtualization_type'] = 'kvm'\n                elif re.match('^vendor_id.*User Mode Linux', line):\n                    self.facts['virtualization_type'] = 'uml'\n                elif re.match('^model name.*UML', line):\n                    self.facts['virtualization_type'] = 'uml'\n                elif re.match('^vendor_id.*PowerVM Lx86', line):\n                    self.facts['virtualization_type'] = 'powervm_lx86'\n                elif re.match('^vendor_id.*IBM/S390', line):\n                    self.facts['virtualization_type'] = 'PR/SM'\n                    lscpu = module.get_bin_path('lscpu')\n                    if lscpu:\n                        rc, out, err = module.run_command([\"lscpu\"])\n                        if rc == 0:\n                            for line in out.split(\"\\n\"):\n                                data = line.split(\":\", 1)\n                                key = data[0].strip()\n                                if key == 'Hypervisor':\n                                    self.facts['virtualization_type'] = data[1].strip()\n                    else:\n                        self.facts['virtualization_type'] = 'ibm_systemz'\n                else:\n                    continue\n                if self.facts['virtualization_type'] == 'PR/SM':\n                    self.facts['virtualization_role'] = 'LPAR'\n                else:\n                    self.facts['virtualization_role'] = 'guest'\n                return\n\n        # Beware that we can have both kvm and virtualbox running on a single system\n        if os.path.exists(\"/proc/modules\") and os.access('/proc/modules', os.R_OK):\n            modules = []\n            for line in open(\"/proc/modules\").readlines():\n                data = line.split(\" \", 1)\n                modules.append(data[0])\n\n            if 'kvm' in modules:\n                self.facts['virtualization_type'] = 'kvm'\n                self.facts['virtualization_role'] = 'host'\n                return\n\n            if 'vboxdrv' in modules:\n                self.facts['virtualization_type'] = 'virtualbox'\n                self.facts['virtualization_role'] = 'host'\n                return\n\n        # If none of the above matches, return 'NA' for virtualization_type\n        # and virtualization_role. This allows for proper grouping.\n        self.facts['virtualization_type'] = 'NA'\n        self.facts['virtualization_role'] = 'NA'\n        return\n\n\nclass HPUXVirtual(Virtual):\n    \"\"\"\n    This is a HP-UX specific subclass of Virtual. It defines\n    - virtualization_type\n    - virtualization_role\n    \"\"\"\n    platform = 'HP-UX'\n\n    def __init__(self):\n        Virtual.__init__(self)\n\n    def populate(self):\n        self.get_virtual_facts()\n        return self.facts\n\n    def get_virtual_facts(self):\n        if os.path.exists('/usr/sbin/vecheck'):\n            rc, out, err = module.run_command(\"/usr/sbin/vecheck\")\n            if rc == 0:\n                self.facts['virtualization_type'] = 'guest'\n                self.facts['virtualization_role'] = 'HP vPar'\n        if os.path.exists('/opt/hpvm/bin/hpvminfo'):\n            rc, out, err = module.run_command(\"/opt/hpvm/bin/hpvminfo\")\n            if rc == 0 and re.match('.*Running.*HPVM vPar.*', out):\n                self.facts['virtualization_type'] = 'guest'\n                self.facts['virtualization_role'] = 'HPVM vPar'\n            elif rc == 0 and re.match('.*Running.*HPVM guest.*', out):\n                self.facts['virtualization_type'] = 'guest'\n                self.facts['virtualization_role'] = 'HPVM IVM'\n            elif rc == 0 and re.match('.*Running.*HPVM host.*', out):\n                self.facts['virtualization_type'] = 'host'\n                self.facts['virtualization_role'] = 'HPVM'\n        if os.path.exists('/usr/sbin/parstatus'):\n            rc, out, err = module.run_command(\"/usr/sbin/parstatus\")\n            if rc == 0:\n                self.facts['virtualization_type'] = 'guest'\n                self.facts['virtualization_role'] = 'HP nPar'\n\n\nclass SunOSVirtual(Virtual):\n    \"\"\"\n    This is a SunOS-specific subclass of Virtual.  It defines\n    - virtualization_type\n    - virtualization_role\n    - container\n    \"\"\"\n    platform = 'SunOS'\n\n    def __init__(self):\n        Virtual.__init__(self)\n\n    def populate(self):\n        self.get_virtual_facts()\n        return self.facts\n\n    def get_virtual_facts(self):\n        rc, out, err = module.run_command(\"/usr/sbin/prtdiag\")\n        for line in out.split('\\n'):\n            if 'VMware' in line:\n                self.facts['virtualization_type'] = 'vmware'\n                self.facts['virtualization_role'] = 'guest'\n            if 'Parallels' in line:\n                self.facts['virtualization_type'] = 'parallels'\n                self.facts['virtualization_role'] = 'guest'\n            if 'VirtualBox' in line:\n                self.facts['virtualization_type'] = 'virtualbox'\n                self.facts['virtualization_role'] = 'guest'\n            if 'HVM domU' in line:\n                self.facts['virtualization_type'] = 'xen'\n                self.facts['virtualization_role'] = 'guest'\n        # Check if it's a zone\n        if os.path.exists(\"/usr/bin/zonename\"):\n            rc, out, err = module.run_command(\"/usr/bin/zonename\")\n            if out.rstrip() != \"global\":\n                self.facts['container'] = 'zone'\n        # Check if it's a branded zone (i.e. Solaris 8/9 zone)\n        if os.path.isdir('/.SUNWnative'):\n            self.facts['container'] = 'zone'\n        # If it's a zone check if we can detect if our global zone is itself virtualized.\n        # Relies on the \"guest tools\" (e.g. vmware tools) to be installed\n        if 'container' in self.facts and self.facts['container'] == 'zone':\n            rc, out, err = module.run_command(\"/usr/sbin/modinfo\")\n            for line in out.split('\\n'):\n                if 'VMware' in line:\n                    self.facts['virtualization_type'] = 'vmware'\n                    self.facts['virtualization_role'] = 'guest'\n                if 'VirtualBox' in line:\n                    self.facts['virtualization_type'] = 'virtualbox'\n                    self.facts['virtualization_role'] = 'guest'\n\ndef get_file_content(path, default=None):\n    data = default\n    if os.path.exists(path) and os.access(path, os.R_OK):\n        data = open(path).read().strip()\n        if len(data) == 0:\n            data = default\n    return data\n\ndef ansible_facts(module):\n    facts = {}\n    facts.update(Facts().populate())\n    facts.update(Hardware().populate())\n    facts.update(Network(module).populate())\n    facts.update(Virtual().populate())\n    return facts\n\n# ===========================================\n\ndef get_all_facts(module):\n\n    setup_options = dict(module_setup=True)\n    facts = ansible_facts(module)\n\n    for (k, v) in facts.items():\n        setup_options[\"ansible_%s\" % k.replace('-', '_')] = v\n\n    # Look for the path to the facter and ohai binary and set\n    # the variable to that path.\n\n    facter_path = module.get_bin_path('facter')\n    ohai_path = module.get_bin_path('ohai')\n\n    # if facter is installed, and we can use --json because\n    # ruby-json is ALSO installed, include facter data in the JSON\n\n    if facter_path is not None:\n        rc, out, err = module.run_command(facter_path + \" --json\")\n        facter = True\n        try:\n            facter_ds = json.loads(out)\n        except:\n            facter = False\n        if facter:\n            for (k,v) in facter_ds.items():\n                setup_options[\"facter_%s\" % k] = v\n\n    # ditto for ohai\n\n    if ohai_path is not None:\n        rc, out, err = module.run_command(ohai_path)\n        ohai = True\n        try:\n            ohai_ds = json.loads(out)\n        except:\n            ohai = False\n        if ohai:\n            for (k,v) in ohai_ds.items():\n                k2 = \"ohai_%s\" % k.replace('-', '_')\n                setup_options[k2] = v\n\n    setup_result = { 'ansible_facts': {} }\n\n    for (k,v) in setup_options.items():\n        if module.params['filter'] == '*' or fnmatch.fnmatch(k, module.params['filter']):\n            setup_result['ansible_facts'][k] = v\n\n    # hack to keep --verbose from showing all the setup module results\n    setup_result['verbose_override'] = True\n\n    return setup_result\n\n","markers":{"markers":{"1":{"id":1,"range":[[0,0],[0,0]],"tailed":false,"reversed":false,"valid":true,"invalidate":"never","persistent":true,"properties":{"type":"selection","editorId":186},"deserializer":"Marker"}},"deserializer":"MarkerManager"},"history":{"undoStack":[],"redoStack":[],"deserializer":"History"},"filePath":"/Users/etrikp/git/ansible/lib/ansible/module_utils/facts.py","modifiedWhenLastPersisted":false,"digestWhenLastPersisted":"3e65a6aa965d6c6530ffa69638b403871936f102","deserializer":"TextBuffer"},{"text":"#!/usr/bin/python\n# -*- coding: utf-8 -*-\n\n# (c) 2012-2013, Timothy Appnel <tim@appnel.com>\n#\n# Ansible is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# Ansible is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.\n\nimport os.path\n\nfrom ansible import utils\nfrom ansible.runner.return_data import ReturnData\nimport ansible.utils.template as template\n\nclass ActionModule(object):\n\n    def __init__(self, runner):\n        self.runner = runner\n        self.inject = None\n\n    def _get_absolute_path(self, path=None):\n        if 'vars' in self.inject:\n            if '_original_file' in self.inject['vars']:\n                # roles\n                original_path = path\n                path = utils.path_dwim_relative(self.inject['_original_file'], 'files', path, self.runner.basedir)\n                if original_path and original_path[-1] == '/' and path[-1] != '/':\n                    # make sure the dwim'd path ends in a trailing \"/\"\n                    # if the original path did\n                    path += '/'\n\n        return path\n\n    def _process_origin(self, host, path, user):\n\n        if not host in ['127.0.0.1', 'localhost']:\n            if user:\n                return '%s@%s:%s' % (user, host, path)\n            else:\n                return '%s:%s' % (host, path)\n        else:\n            if not ':' in path:\n                if not path.startswith('/'):\n                    path = self._get_absolute_path(path=path)\n            return path\n\n    def _process_remote(self, host, path, user):\n        transport = self.runner.transport\n        return_data = None\n        if not host in ['127.0.0.1', 'localhost'] or transport != \"local\":\n            if user:\n                return_data = '%s@%s:%s' % (user, host, path)\n            else:\n                return_data = '%s:%s' % (host, path)\n        else:\n            return_data = path\n\n        if not ':' in return_data:\n            if not return_data.startswith('/'):\n                return_data = self._get_absolute_path(path=return_data)\n\n        return return_data\n\n    def setup(self, module_name, inject):\n        ''' Always default to localhost as delegate if None defined '''\n   \n        self.inject = inject\n    \n        # Store original transport and sudo values.\n        self.original_transport = inject.get('ansible_connection', self.runner.transport)\n        self.original_sudo = self.runner.sudo\n        self.transport_overridden = False\n\n        if inject.get('delegate_to') is None:\n            inject['delegate_to'] = '127.0.0.1'\n            # IF original transport is not local, override transport and disable sudo.\n            if self.original_transport != 'local':\n                inject['ansible_connection'] = 'local'\n                self.transport_overridden = True\n                self.runner.sudo = False\n\n    def run(self, conn, tmp, module_name, module_args,\n        inject, complex_args=None, **kwargs):\n\n        ''' generates params and passes them on to the rsync module '''\n\n        self.inject = inject\n\n        # load up options\n        options = {}\n        if complex_args:\n            options.update(complex_args)\n        options.update(utils.parse_kv(module_args))\n\n        src = options.get('src', None)\n        dest = options.get('dest', None)\n\n        src = template.template(self.runner.basedir, src, inject)\n        dest = template.template(self.runner.basedir, dest, inject)\n\n        try:\n            options['local_rsync_path'] = inject['ansible_rsync_path']\n        except KeyError:\n            pass\n\n        # from the perspective of the rsync call the delegate is the localhost\n        src_host = '127.0.0.1'\n        dest_host = inject.get('ansible_ssh_host', inject['inventory_hostname'])\n\n        # allow ansible_ssh_host to be templated\n        dest_host = template.template(self.runner.basedir, dest_host, inject, fail_on_undefined=True)\n        dest_is_local = dest_host in ['127.0.0.1', 'localhost']\n\n        # CHECK FOR NON-DEFAULT SSH PORT\n        dest_port = options.get('dest_port')\n        inv_port = inject.get('ansible_ssh_port', inject['inventory_hostname'])\n        if inv_port != dest_port and inv_port != inject['inventory_hostname']:\n            options['dest_port'] = inv_port\n\n        # edge case: explicit delegate and dest_host are the same\n        if dest_host == inject['delegate_to']:\n            dest_host = '127.0.0.1'\n\n        # SWITCH SRC AND DEST PER MODE\n        if options.get('mode', 'push') == 'pull':\n            (dest_host, src_host) = (src_host, dest_host)\n\n        # CHECK DELEGATE HOST INFO\n        use_delegate = False\n        if conn.delegate != conn.host:\n            if 'hostvars' in inject:\n                if conn.delegate in inject['hostvars'] and self.original_transport != 'local':\n                    # use a delegate host instead of localhost\n                    use_delegate = True\n\n        # COMPARE DELEGATE, HOST AND TRANSPORT                             \n        process_args = False\n        if not dest_host is src_host and self.original_transport != 'local':\n            # interpret and inject remote host info into src or dest\n            process_args = True\n\n        # MUNGE SRC AND DEST PER REMOTE_HOST INFO\n        if process_args or use_delegate:\n\n            user = None\n            if utils.boolean(options.get('set_remote_user', 'yes')):\n                if use_delegate:\n                    user = inject['hostvars'][conn.delegate].get('ansible_ssh_user')\n\n                if not use_delegate or not user:\n                    user = inject.get('ansible_ssh_user',\n                                    self.runner.remote_user)\n                \n            if use_delegate:\n                # FIXME\n                private_key = inject.get('ansible_ssh_private_key_file', self.runner.private_key_file)\n            else:\n                private_key = inject.get('ansible_ssh_private_key_file', self.runner.private_key_file)\n\n            private_key = template.template(self.runner.basedir, private_key, inject, fail_on_undefined=True)\n\n            if not private_key is None:\n                private_key = os.path.expanduser(private_key)\n                options['private_key'] = private_key\n                \n            # use the mode to define src and dest's url\n            if options.get('mode', 'push') == 'pull':\n                # src is a remote path: <user>@<host>, dest is a local path\n                src = self._process_remote(src_host, src, user)\n                dest = self._process_origin(dest_host, dest, user)\n            else:\n                # src is a local path, dest is a remote path: <user>@<host>\n                src = self._process_origin(src_host, src, user)\n                dest = self._process_remote(dest_host, dest, user)\n\n        options['src'] = src\n        options['dest'] = dest\n        if 'mode' in options:\n            del options['mode']\n\n        # Allow custom rsync path argument.\n        rsync_path = options.get('rsync_path', None)\n\n        # If no rsync_path is set, sudo was originally set, and dest is remote then add 'sudo rsync' argument.\n        if not rsync_path and self.transport_overridden and self.original_sudo and not dest_is_local:\n            rsync_path = 'sudo rsync'\n\n        # make sure rsync path is quoted.\n        if rsync_path:\n            options['rsync_path'] = '\"' + rsync_path + '\"'\n\n        module_args = \"\"\n        if self.runner.noop_on_check(inject):\n            module_args = \"CHECKMODE=True\"\n\n        # run the module and store the result\n        result = self.runner._execute_module(conn, tmp, 'synchronize', module_args, complex_args=options, inject=inject)\n\n        # reset the sudo property                 \n        self.runner.sudo = self.original_sudo\n\n        return result\n\n","markers":{"markers":{"1":{"id":1,"range":[[0,0],[0,0]],"tailed":false,"reversed":false,"valid":true,"invalidate":"never","persistent":true,"properties":{"type":"selection","editorId":236},"deserializer":"Marker"}},"deserializer":"MarkerManager"},"history":{"undoStack":[],"redoStack":[],"deserializer":"History"},"filePath":"/Users/etrikp/git/ansible/lib/ansible/runner/action_plugins/synchronize.py","modifiedWhenLastPersisted":false,"digestWhenLastPersisted":"86acc5c807bcb23653cef9afa8088191ba2d07a5","deserializer":"TextBuffer"},{"text":"# Copyright 2012, Jeroen Hoekx <jeroen@hoekx.be>\n#\n# This file is part of Ansible\n#\n# Ansible is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# Ansible is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.\n\nimport ansible\n\nfrom ansible.callbacks import vv\nfrom ansible.errors import AnsibleError as ae\nfrom ansible.runner.return_data import ReturnData\nfrom ansible.utils import parse_kv, check_conditional\nimport ansible.utils.template as template\n\nclass ActionModule(object):\n    ''' Create inventory groups based on variables '''\n\n    ### We need to be able to modify the inventory\n    BYPASS_HOST_LOOP = True\n    TRANSFERS_FILES = False\n\n    def __init__(self, runner):\n        self.runner = runner\n\n    def run(self, conn, tmp, module_name, module_args, inject, complex_args=None, **kwargs):\n\n        # the group_by module does not need to pay attention to check mode.\n        # it always runs.\n\n        # module_args and complex_args have already been templated for the first host.\n        # Use them here only to check that a key argument is provided.\n        args = {}\n        if complex_args:\n            args.update(complex_args)\n        args.update(parse_kv(module_args))\n        if not 'key' in args:\n            raise ae(\"'key' is a required argument.\")\n\n        vv(\"created 'group_by' ActionModule: key=%s\"%(args['key']))\n\n        inventory = self.runner.inventory\n\n        result = {'changed': False}\n\n        ### find all groups\n        groups = {}\n\n        for host in self.runner.host_set:\n            data = {}\n            data.update(inject)\n            data.update(inject['hostvars'][host])\n            conds = self.runner.conditional\n            if type(conds) != list:\n                conds = [ conds ]\n            next_host = False\n            for cond in conds:\n                if not check_conditional(cond, self.runner.basedir, data, fail_on_undefined=self.runner.error_on_undefined_vars):\n                    next_host = True\n                    break\n            if next_host:\n                continue\n\n            # Template original module_args and complex_args from runner for each host.\n            host_module_args = template.template(self.runner.basedir, self.runner.module_args, data)\n            host_complex_args = template.template(self.runner.basedir, self.runner.complex_args, data)\n            host_args  = {}\n            if host_complex_args:\n                host_args.update(host_complex_args)\n            host_args.update(parse_kv(host_module_args))\n\n            group_name = host_args['key']\n            group_name = group_name.replace(' ','-')\n            if group_name not in groups:\n                groups[group_name] = []\n            groups[group_name].append(host)\n\n        result['groups'] = groups\n\n        ### add to inventory\n        for group, hosts in groups.items():\n            inv_group = inventory.get_group(group)\n            if not inv_group:\n                inv_group = ansible.inventory.Group(name=group)\n                inventory.add_group(inv_group)\n                inventory.get_group('all').add_child_group(inv_group)\n                inv_group.vars = inventory.get_group_variables(group, update_cached=False, vault_password=inventory._vault_password)\n            for host in hosts:\n                if host in self.runner.inventory._vars_per_host:\n                    del self.runner.inventory._vars_per_host[host]\n                inv_host = inventory.get_host(host)\n                if not inv_host:\n                    inv_host = ansible.inventory.Host(name=host)\n                if inv_group not in inv_host.get_groups():\n                    result['changed'] = True\n                    inv_group.add_host(inv_host)\n\n        return ReturnData(conn=conn, comm_ok=True, result=result)\n","markers":{"markers":{"1":{"id":1,"range":[[0,0],[0,0]],"tailed":false,"reversed":false,"valid":true,"invalidate":"never","persistent":true,"properties":{"type":"selection","editorId":240},"deserializer":"Marker"}},"deserializer":"MarkerManager"},"history":{"undoStack":[],"redoStack":[],"deserializer":"History"},"filePath":"/Users/etrikp/git/ansible/lib/ansible/runner/action_plugins/group_by.py","modifiedWhenLastPersisted":false,"digestWhenLastPersisted":"3715d5fe2af814f6f7351a1106819dc0bb2a9098","deserializer":"TextBuffer"},{"text":"# (c) 2012-2014, Michael DeHaan <michael.dehaan@gmail.com>\n#\n# This file is part of Ansible\n#\n# Ansible is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# Ansible is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.\n\nimport os\n\nfrom ansible import utils\nimport ansible.constants as C\nimport ansible.utils.template as template\nfrom ansible import errors\nfrom ansible.runner.return_data import ReturnData\nimport base64\nimport json\nimport stat\nimport tempfile\nimport pipes\n\n## fixes https://github.com/ansible/ansible/issues/3518\n# http://mypy.pythonblogs.com/12_mypy/archive/1253_workaround_for_python_bug_ascii_codec_cant_encode_character_uxa0_in_position_111_ordinal_not_in_range128.html\nimport sys\nreload(sys)\nsys.setdefaultencoding(\"utf8\")\n\n\nclass ActionModule(object):\n\n    def __init__(self, runner):\n        self.runner = runner\n\n    def run(self, conn, tmp_path, module_name, module_args, inject, complex_args=None, **kwargs):\n        ''' handler for file transfer operations '''\n\n        # load up options\n        options = {}\n        if complex_args:\n            options.update(complex_args)\n        options.update(utils.parse_kv(module_args))\n        source  = options.get('src', None)\n        content = options.get('content', None)\n        dest    = options.get('dest', None)\n        raw     = utils.boolean(options.get('raw', 'no'))\n        force   = utils.boolean(options.get('force', 'yes'))\n\n        # content with newlines is going to be escaped to safely load in yaml\n        # now we need to unescape it so that the newlines are evaluated properly\n        # when writing the file to disk\n        if content:\n            if isinstance(content, unicode):\n                try:\n                    content = content.decode('unicode-escape')\n                except UnicodeDecodeError:\n                    pass\n\n        if (source is None and content is None and not 'first_available_file' in inject) or dest is None:\n            result=dict(failed=True, msg=\"src (or content) and dest are required\")\n            return ReturnData(conn=conn, result=result)\n        elif (source is not None or 'first_available_file' in inject) and content is not None:\n            result=dict(failed=True, msg=\"src and content are mutually exclusive\")\n            return ReturnData(conn=conn, result=result)\n\n        # Check if the source ends with a \"/\"\n        source_trailing_slash = False\n        if source:\n            source_trailing_slash = source.endswith(\"/\")\n\n        # Define content_tempfile in case we set it after finding content populated.\n        content_tempfile = None\n\n        # If content is defined make a temp file and write the content into it.\n        if content is not None:\n            try:\n                # If content comes to us as a dict it should be decoded json.\n                # We need to encode it back into a string to write it out.\n                if type(content) is dict:\n                    content_tempfile = self._create_content_tempfile(json.dumps(content))\n                else:\n                    content_tempfile = self._create_content_tempfile(content)\n                source = content_tempfile\n            except Exception, err:\n                result = dict(failed=True, msg=\"could not write content temp file: %s\" % err)\n                return ReturnData(conn=conn, result=result)\n        # if we have first_available_file in our vars\n        # look up the files and use the first one we find as src\n        elif 'first_available_file' in inject:\n            found = False\n            for fn in inject.get('first_available_file'):\n                fn_orig = fn\n                fnt = template.template(self.runner.basedir, fn, inject)\n                fnd = utils.path_dwim(self.runner.basedir, fnt)\n                if not os.path.exists(fnd) and '_original_file' in inject:\n                    fnd = utils.path_dwim_relative(inject['_original_file'], 'files', fnt, self.runner.basedir, check=False)\n                if os.path.exists(fnd):\n                    source = fnd\n                    found = True\n                    break\n            if not found:\n                results = dict(failed=True, msg=\"could not find src in first_available_file list\")\n                return ReturnData(conn=conn, result=results)\n        else:\n            source = template.template(self.runner.basedir, source, inject)\n            if '_original_file' in inject:\n                source = utils.path_dwim_relative(inject['_original_file'], 'files', source, self.runner.basedir)\n            else:\n                source = utils.path_dwim(self.runner.basedir, source)\n\n        # A list of source file tuples (full_path, relative_path) which will try to copy to the destination\n        source_files = []\n\n        # If source is a directory populate our list else source is a file and translate it to a tuple.\n        if os.path.isdir(source):\n            # Get the amount of spaces to remove to get the relative path.\n            if source_trailing_slash:\n                sz = len(source) + 1\n            else:\n                sz = len(source.rsplit('/', 1)[0]) + 1\n\n            # Walk the directory and append the file tuples to source_files.\n            for base_path, sub_folders, files in os.walk(source):\n                for file in files:\n                    full_path = os.path.join(base_path, file)\n                    rel_path = full_path[sz:]\n                    source_files.append((full_path, rel_path))\n\n            # If it's recursive copy, destination is always a dir,\n            # explicitly mark it so (note - copy module relies on this).\n            if not conn.shell.path_has_trailing_slash(dest):\n                dest = conn.shell.join_path(dest, '')\n        else:\n            source_files.append((source, os.path.basename(source)))\n\n        changed = False\n        diffs = []\n        module_result = {\"changed\": False}\n\n        # A register for if we executed a module.\n        # Used to cut down on command calls when not recursive.\n        module_executed = False\n\n        # Tell _execute_module to delete the file if there is one file.\n        delete_remote_tmp = (len(source_files) == 1)\n\n        # If this is a recursive action create a tmp_path that we can share as the _exec_module create is too late.\n        if not delete_remote_tmp:\n            if \"-tmp-\" not in tmp_path:\n                tmp_path = self.runner._make_tmp_path(conn)\n\n        for source_full, source_rel in source_files:\n            # Generate the MD5 hash of the local file.\n            local_md5 = utils.md5(source_full)\n\n            # If local_md5 is not defined we can't find the file so we should fail out.\n            if local_md5 is None:\n                result = dict(failed=True, msg=\"could not find src=%s\" % source_full)\n                return ReturnData(conn=conn, result=result)\n\n            # This is kind of optimization - if user told us destination is\n            # dir, do path manipulation right away, otherwise we still check\n            # for dest being a dir via remote call below.\n            if conn.shell.path_has_trailing_slash(dest):\n                dest_file = conn.shell.join_path(dest, source_rel)\n            else:\n                dest_file = conn.shell.join_path(dest)\n\n            # Attempt to get the remote MD5 Hash.\n            remote_md5 = self.runner._remote_md5(conn, tmp_path, dest_file)\n\n            if remote_md5 == '3':\n                # The remote_md5 was executed on a directory.\n                if content is not None:\n                    # If source was defined as content remove the temporary file and fail out.\n                    self._remove_tempfile_if_content_defined(content, content_tempfile)\n                    result = dict(failed=True, msg=\"can not use content with a dir as dest\")\n                    return ReturnData(conn=conn, result=result)\n                else:\n                    # Append the relative source location to the destination and retry remote_md5.\n                    dest_file = conn.shell.join_path(dest, source_rel)\n                    remote_md5 = self.runner._remote_md5(conn, tmp_path, dest_file)\n\n            if remote_md5 != '1' and not force:\n                # remote_file does not exist so continue to next iteration.\n                continue\n\n            if local_md5 != remote_md5:\n                # The MD5 hashes don't match and we will change or error out.\n                changed = True\n\n                # Create a tmp_path if missing only if this is not recursive.\n                # If this is recursive we already have a tmp_path.\n                if delete_remote_tmp:\n                    if \"-tmp-\" not in tmp_path:\n                        tmp_path = self.runner._make_tmp_path(conn)\n\n                if self.runner.diff and not raw:\n                    diff = self._get_diff_data(conn, tmp_path, inject, dest_file, source_full)\n                else:\n                    diff = {}\n\n                if self.runner.noop_on_check(inject):\n                    self._remove_tempfile_if_content_defined(content, content_tempfile)\n                    diffs.append(diff)\n                    changed = True\n                    module_result = dict(changed=True)\n                    continue\n\n                # Define a remote directory that we will copy the file to.\n                tmp_src = tmp_path + 'source'\n\n                if not raw:\n                    conn.put_file(source_full, tmp_src)\n                else:\n                    conn.put_file(source_full, dest_file)\n\n                # We have copied the file remotely and no longer require our content_tempfile\n                self._remove_tempfile_if_content_defined(content, content_tempfile)\n\n                # fix file permissions when the copy is done as a different user\n                if self.runner.sudo and self.runner.sudo_user != 'root' and not raw:\n                    self.runner._remote_chmod(conn, 'a+r', tmp_src, tmp_path)\n\n                if raw:\n                    # Continue to next iteration if raw is defined.\n                    continue\n\n                # Run the copy module\n\n                # src and dest here come after original and override them\n                # we pass dest only to make sure it includes trailing slash in case of recursive copy\n                new_module_args = dict(\n                    src=tmp_src,\n                    dest=dest,\n                    original_basename=source_rel\n                )\n                if self.runner.noop_on_check(inject):\n                    new_module_args['CHECKMODE'] = True\n                if self.runner.no_log:\n                    new_module_args['NO_LOG'] = True\n\n                module_args_tmp = utils.merge_module_args(module_args, new_module_args)\n\n                module_return = self.runner._execute_module(conn, tmp_path, 'copy', module_args_tmp, inject=inject, complex_args=complex_args, delete_remote_tmp=delete_remote_tmp)\n                module_executed = True\n\n            else:\n                # no need to transfer the file, already correct md5, but still need to call\n                # the file module in case we want to change attributes\n                self._remove_tempfile_if_content_defined(content, content_tempfile)\n\n                if raw:\n                    # Continue to next iteration if raw is defined.\n                    # self.runner._remove_tmp_path(conn, tmp_path)\n                    continue\n\n                tmp_src = tmp_path + source_rel\n\n                # Build temporary module_args.\n                new_module_args = dict(\n                    src=tmp_src,\n                    dest=dest,\n                    original_basename=source_rel\n                )\n                if self.runner.noop_on_check(inject):\n                    new_module_args['CHECKMODE'] = True\n                if self.runner.no_log:\n                    new_module_args['NO_LOG'] = True\n\n                module_args_tmp = utils.merge_module_args(module_args, new_module_args)\n\n                # Execute the file module.\n                module_return = self.runner._execute_module(conn, tmp_path, 'file', module_args_tmp, inject=inject, complex_args=complex_args, delete_remote_tmp=delete_remote_tmp)\n                module_executed = True\n\n            module_result = module_return.result\n            if not module_result.get('md5sum'):\n                module_result['md5sum'] = local_md5\n            if module_result.get('failed') == True:\n                return module_return\n            if module_result.get('changed') == True:\n                changed = True\n\n        # Delete tmp_path if we were recursive or if we did not execute a module.\n        if (not C.DEFAULT_KEEP_REMOTE_FILES and not delete_remote_tmp) \\\n            or (not C.DEFAULT_KEEP_REMOTE_FILES and delete_remote_tmp and not module_executed):\n            self.runner._remove_tmp_path(conn, tmp_path)\n\n        # the file module returns the file path as 'path', but \n        # the copy module uses 'dest', so add it if it's not there\n        if 'path' in module_result and 'dest' not in module_result:\n            module_result['dest'] = module_result['path']\n\n        # TODO: Support detailed status/diff for multiple files\n        if len(source_files) == 1:\n            result = module_result\n        else:\n            result = dict(dest=dest, src=source, changed=changed)\n        if len(diffs) == 1:\n            return ReturnData(conn=conn, result=result, diff=diffs[0])\n        else:\n            return ReturnData(conn=conn, result=result)\n\n    def _create_content_tempfile(self, content):\n        ''' Create a tempfile containing defined content '''\n        fd, content_tempfile = tempfile.mkstemp()\n        f = os.fdopen(fd, 'w')\n        try:\n            f.write(content)\n        except Exception, err:\n            os.remove(content_tempfile)\n            raise Exception(err)\n        finally:\n            f.close()\n        return content_tempfile\n\n    def _get_diff_data(self, conn, tmp, inject, destination, source):\n        peek_result = self.runner._execute_module(conn, tmp, 'file', \"path=%s diff_peek=1\" % destination, inject=inject, persist_files=True)\n\n        if not peek_result.is_successful():\n            return {}\n\n        diff = {}\n        if peek_result.result['state'] == 'absent':\n            diff['before'] = ''\n        elif peek_result.result['appears_binary']:\n            diff['dst_binary'] = 1\n        elif peek_result.result['size'] > utils.MAX_FILE_SIZE_FOR_DIFF:\n            diff['dst_larger'] = utils.MAX_FILE_SIZE_FOR_DIFF\n        else:\n            dest_result = self.runner._execute_module(conn, tmp, 'slurp', \"path=%s\" % destination, inject=inject, persist_files=True)\n            if 'content' in dest_result.result:\n                dest_contents = dest_result.result['content']\n                if dest_result.result['encoding'] == 'base64':\n                    dest_contents = base64.b64decode(dest_contents)\n                else:\n                    raise Exception(\"unknown encoding, failed: %s\" % dest_result.result)\n                diff['before_header'] = destination\n                diff['before'] = dest_contents\n\n        src = open(source)\n        src_contents = src.read(8192)\n        st = os.stat(source)\n        if \"\\x00\" in src_contents:\n            diff['src_binary'] = 1\n        elif st[stat.ST_SIZE] > utils.MAX_FILE_SIZE_FOR_DIFF:\n            diff['src_larger'] = utils.MAX_FILE_SIZE_FOR_DIFF\n        else:\n            src.seek(0)\n            diff['after_header'] = source\n            diff['after'] = src.read()\n\n        return diff\n\n    def _remove_tempfile_if_content_defined(self, content, content_tempfile):\n        if content is not None:\n            os.remove(content_tempfile)\n\n    \n    def _result_key_merge(self, options, results):\n        # add keys to file module results to mimic copy\n        if 'path' in results.result and 'dest' not in results.result:\n            results.result['dest'] = results.result['path']\n            del results.result['path']\n        return results\n","markers":{"markers":{"1":{"id":1,"range":[[0,0],[0,0]],"tailed":false,"reversed":false,"valid":true,"invalidate":"never","persistent":true,"properties":{"type":"selection","editorId":244},"deserializer":"Marker"}},"deserializer":"MarkerManager"},"history":{"undoStack":[],"redoStack":[],"deserializer":"History"},"filePath":"/Users/etrikp/git/ansible/lib/ansible/runner/action_plugins/copy.py","modifiedWhenLastPersisted":false,"digestWhenLastPersisted":"1736775905a7d96baff42d5145b8f60a7d797990","deserializer":"TextBuffer"},{"text":"# (c) 2013-2014, Michael DeHaan <michael.dehaan@gmail.com>\n#           Stephen Fromm <sfromm@gmail.com>\n#           Brian Coca  <briancoca+dev@gmail.com>\n#\n# This file is part of Ansible\n#\n# Ansible is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# Ansible is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n\nimport os\nimport os.path\nimport pipes\nimport shutil\nimport tempfile\nimport base64\nimport re\nfrom ansible import utils\nfrom ansible.runner.return_data import ReturnData\n\nclass ActionModule(object):\n\n    TRANSFERS_FILES = True\n\n    def __init__(self, runner):\n        self.runner = runner\n\n    def _assemble_from_fragments(self, src_path, delimiter=None, compiled_regexp=None):\n        ''' assemble a file from a directory of fragments '''\n        tmpfd, temp_path = tempfile.mkstemp()\n        tmp = os.fdopen(tmpfd,'w')\n        delimit_me = False\n        add_newline = False\n\n        for f in sorted(os.listdir(src_path)):\n            if compiled_regexp and not compiled_regexp.search(f):\n                continue\n            fragment = \"%s/%s\" % (src_path, f)\n            if not os.path.isfile(fragment):\n                continue\n            fragment_content = file(fragment).read()\n\n            # always put a newline between fragments if the previous fragment didn't end with a newline.\n            if add_newline:\n                tmp.write('\\n')\n\n            # delimiters should only appear between fragments\n            if delimit_me:\n                if delimiter:\n                    # un-escape anything like newlines\n                    delimiter = delimiter.decode('unicode-escape')\n                    tmp.write(delimiter)\n                    # always make sure there's a newline after the\n                    # delimiter, so lines don't run together\n                    if delimiter[-1] != '\\n':\n                        tmp.write('\\n')\n\n            tmp.write(fragment_content)\n            delimit_me = True\n            if fragment_content.endswith('\\n'):\n                add_newline = False\n            else:\n                add_newline = True\n\n        tmp.close()\n        return temp_path\n\n    def run(self, conn, tmp, module_name, module_args, inject, complex_args=None, **kwargs):\n\n        # load up options\n        options  = {}\n        if complex_args:\n            options.update(complex_args)\n\n        options.update(utils.parse_kv(module_args))\n\n        src = options.get('src', None)\n        dest = options.get('dest', None)\n        delimiter = options.get('delimiter', None)\n        remote_src = utils.boolean(options.get('remote_src', 'yes'))\n        regexp = options.get('regexp', None)\n\n\n        if src is None or dest is None:\n            result = dict(failed=True, msg=\"src and dest are required\")\n            return ReturnData(conn=conn, comm_ok=False, result=result)\n\n        if remote_src:\n            return self.runner._execute_module(conn, tmp, 'assemble', module_args, inject=inject, complex_args=complex_args)\n        elif '_original_file' in inject:\n            src = utils.path_dwim_relative(inject['_original_file'], 'files', src, self.runner.basedir)\n        else:\n            # the source is local, so expand it here\n            src = os.path.expanduser(src)\n\n        _re = None\n        if regexp is not None:\n            _re = re.compile(regexp)\n\n        # Does all work assembling the file\n        path = self._assemble_from_fragments(src, delimiter, _re)\n\n        pathmd5 = utils.md5s(path)\n        remote_md5 = self.runner._remote_md5(conn, tmp, dest)\n\n        if pathmd5 != remote_md5:\n            resultant = file(path).read()\n            if self.runner.diff:\n                dest_result = self.runner._execute_module(conn, tmp, 'slurp', \"path=%s\" % dest, inject=inject, persist_files=True)\n                if 'content' in dest_result.result:\n                    dest_contents = dest_result.result['content']\n                    if dest_result.result['encoding'] == 'base64':\n                        dest_contents = base64.b64decode(dest_contents)\n                    else:\n                        raise Exception(\"unknown encoding, failed: %s\" % dest_result.result)\n            xfered = self.runner._transfer_str(conn, tmp, 'src', resultant)\n\n            # fix file permissions when the copy is done as a different user\n            if self.runner.sudo and self.runner.sudo_user != 'root':\n                self.runner._remote_chmod(conn, 'a+r', xfered, tmp)\n\n            # run the copy module\n            new_module_args = dict(\n                src=xfered,\n                dest=dest,\n                original_basename=os.path.basename(src),\n            )\n            module_args_tmp = utils.merge_module_args(module_args, new_module_args)\n\n            if self.runner.noop_on_check(inject):\n                return ReturnData(conn=conn, comm_ok=True, result=dict(changed=True), diff=dict(before_header=dest, after_header=src, after=resultant))\n            else:\n                res = self.runner._execute_module(conn, tmp, 'copy', module_args_tmp, inject=inject)\n                res.diff = dict(after=resultant)\n                return res\n        else:\n            new_module_args = dict(\n                src=xfered,\n                dest=dest,\n                original_basename=os.path.basename(src),\n            )\n            module_args_tmp = utils.merge_module_args(module_args, new_module_args)\n\n            return self.runner._execute_module(conn, tmp, 'file', module_args_tmp, inject=inject)\n","markers":{"markers":{"1":{"id":1,"range":[[0,0],[0,0]],"tailed":false,"reversed":false,"valid":true,"invalidate":"never","persistent":true,"properties":{"type":"selection","editorId":248},"deserializer":"Marker"}},"deserializer":"MarkerManager"},"history":{"undoStack":[],"redoStack":[],"deserializer":"History"},"filePath":"/Users/etrikp/git/ansible/lib/ansible/runner/action_plugins/assemble.py","modifiedWhenLastPersisted":false,"digestWhenLastPersisted":"1e2af9a546915369eeec9e1a5ea2a3b7177ee962","deserializer":"TextBuffer"},{"text":"# Based on local.py (c) 2012, Michael DeHaan <michael.dehaan@gmail.com>\n# Based on chroot.py (c) 2013, Maykel Moya <mmoya@speedyrails.com>\n# (c) 2013, Michael Scherer <misc@zarb.org>\n#\n# This file is part of Ansible\n#\n# Ansible is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# Ansible is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.\n\nimport distutils.spawn\nimport os\nimport subprocess\nfrom ansible import errors\nfrom ansible.callbacks import vvv\n\nclass Connection(object):\n    ''' Local lxc based connections '''\n\n    def _search_executable(self, executable):\n        cmd = distutils.spawn.find_executable(executable)\n        if not cmd:\n            raise errors.AnsibleError(\"%s command not found in PATH\") % executable\n        return cmd\n\n    def _check_domain(self, domain):\n        p = subprocess.Popen([self.cmd, '-q', '-c', 'lxc:///', 'dominfo', domain],\n                             stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        p.communicate()\n        if p.returncode:\n            raise errors.AnsibleError(\"%s is not a lxc defined in libvirt\" % domain)\n\n    def __init__(self, runner, host, port, *args, **kwargs):\n        self.lxc = host\n\n        self.cmd = self._search_executable('virsh')\n\n        self._check_domain(host)\n\n        self.runner = runner\n        self.host = host\n        # port is unused, since this is local\n        self.port = port\n\n    def connect(self, port=None):\n        ''' connect to the lxc; nothing to do here '''\n\n        vvv(\"THIS IS A LOCAL LXC DIR\", host=self.lxc)\n\n        return self\n\n    def _generate_cmd(self, executable, cmd):\n        if executable:\n            local_cmd = [self.cmd, '-q', '-c', 'lxc:///', 'lxc-enter-namespace', self.lxc, '--', executable , '-c', cmd]\n        else:\n            local_cmd = '%s -q -c lxc:/// lxc-enter-namespace %s -- %s' % (self.cmd, self.lxc, cmd)\n        return local_cmd\n\n    def exec_command(self, cmd, tmp_path, sudo_user, sudoable=False, executable='/bin/sh', in_data=None, su=None, su_user=None):\n        ''' run a command on the chroot '''\n\n        if su or su_user:\n            raise errors.AnsibleError(\"Internal Error: this module does not support running commands via su\")\n\n        if in_data:\n            raise errors.AnsibleError(\"Internal Error: this module does not support optimized module pipelining\")\n\n        # We enter lxc as root so sudo stuff can be ignored\n        local_cmd = self._generate_cmd(executable, cmd)\n\n        vvv(\"EXEC %s\" % (local_cmd), host=self.lxc)\n        p = subprocess.Popen(local_cmd, shell=isinstance(local_cmd, basestring),\n                             cwd=self.runner.basedir,\n                             stdin=subprocess.PIPE,\n                             stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n\n        stdout, stderr = p.communicate()\n        return (p.returncode, '', stdout, stderr)\n\n    def _normalize_path(self, path, prefix):\n        if not path.startswith(os.path.sep):\n            path = os.path.join(os.path.sep, path)\n        normpath = os.path.normpath(path)\n        return os.path.join(prefix, normpath[1:])\n\n    def put_file(self, in_path, out_path):\n        ''' transfer a file from local to lxc '''\n\n        out_path = self._normalize_path(out_path, '/')\n        vvv(\"PUT %s TO %s\" % (in_path, out_path), host=self.lxc)\n        \n        local_cmd = [self.cmd, '-q', '-c', 'lxc:///', 'lxc-enter-namespace', self.lxc, '--', '/bin/tee', out_path]\n        vvv(\"EXEC %s\" % (local_cmd), host=self.lxc)\n\n        p = subprocess.Popen(local_cmd, cwd=self.runner.basedir,\n                             stdin=subprocess.PIPE,\n                             stdout=subprocess.PIPE, stderr=subprocess.PIPE) \n        stdout, stderr = p.communicate(open(in_path,'rb').read())\n \n    def fetch_file(self, in_path, out_path):\n        ''' fetch a file from lxc to local '''\n\n        in_path = self._normalize_path(in_path, '/')\n        vvv(\"FETCH %s TO %s\" % (in_path, out_path), host=self.lxc)\n\n        local_cmd = [self.cmd, '-q', '-c', 'lxc:///', 'lxc-enter-namespace', self.lxc, '--', '/bin/cat', in_path]\n        vvv(\"EXEC %s\" % (local_cmd), host=self.lxc)\n\n        p = subprocess.Popen(local_cmd, cwd=self.runner.basedir,\n                             stdin=subprocess.PIPE,\n                             stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        stdout, stderr = p.communicate()\n        open(out_path,'wb').write(stdout)\n\n\n    def close(self):\n        ''' terminate the connection; nothing to do here '''\n        pass\n","markers":{"markers":{"1":{"id":1,"range":[[0,0],[0,0]],"tailed":false,"reversed":false,"valid":true,"invalidate":"never","persistent":true,"properties":{"type":"selection","editorId":265},"deserializer":"Marker"}},"deserializer":"MarkerManager"},"history":{"undoStack":[],"redoStack":[],"deserializer":"History"},"filePath":"/Users/etrikp/git/ansible/lib/ansible/runner/connection_plugins/libvirt_lxc.py","modifiedWhenLastPersisted":false,"digestWhenLastPersisted":"d07669f64d5e7b54dc94e08c1471022ef70f15af","deserializer":"TextBuffer"},{"text":"# (c) 2012, Michael DeHaan <michael.dehaan@gmail.com>\n#\n# This file is part of Ansible\n#\n# Ansible is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# Ansible is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.\n\nimport traceback\nimport os\nimport pipes\nimport shutil\nimport subprocess\nimport select\nimport fcntl\nfrom ansible import errors\nfrom ansible import utils\nfrom ansible.callbacks import vvv\n\nclass Connection(object):\n    ''' Local based connections '''\n\n    def __init__(self, runner, host, port, *args, **kwargs):\n        self.runner = runner\n        self.host = host\n        # port is unused, since this is local\n        self.port = port \n        self.has_pipelining = False\n\n    def connect(self, port=None):\n        ''' connect to the local host; nothing to do here '''\n\n        return self\n\n    def exec_command(self, cmd, tmp_path, sudo_user=None, sudoable=False, executable='/bin/sh', in_data=None, su=None, su_user=None):\n        ''' run a command on the local host '''\n\n        # su requires to be run from a terminal, and therefore isn't supported here (yet?)\n        if su or su_user:\n            raise errors.AnsibleError(\"Internal Error: this module does not support running commands via su\")\n\n        if in_data:\n            raise errors.AnsibleError(\"Internal Error: this module does not support optimized module pipelining\")\n\n        if not self.runner.sudo or not sudoable:\n            if executable:\n                local_cmd = executable.split() + ['-c', cmd]\n            else:\n                local_cmd = cmd\n        else:\n            local_cmd, prompt, success_key = utils.make_sudo_cmd(sudo_user, executable, cmd)\n        executable = executable.split()[0] if executable else None\n\n        vvv(\"EXEC %s\" % (local_cmd), host=self.host)\n        p = subprocess.Popen(local_cmd, shell=isinstance(local_cmd, basestring),\n                             cwd=self.runner.basedir, executable=executable,\n                             stdin=subprocess.PIPE,\n                             stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n\n        if self.runner.sudo and sudoable and self.runner.sudo_pass:\n            fcntl.fcntl(p.stdout, fcntl.F_SETFL,\n                        fcntl.fcntl(p.stdout, fcntl.F_GETFL) | os.O_NONBLOCK)\n            fcntl.fcntl(p.stderr, fcntl.F_SETFL,\n                        fcntl.fcntl(p.stderr, fcntl.F_GETFL) | os.O_NONBLOCK)\n            sudo_output = ''\n            while not sudo_output.endswith(prompt) and success_key not in sudo_output:\n                rfd, wfd, efd = select.select([p.stdout, p.stderr], [],\n                                              [p.stdout, p.stderr], self.runner.timeout)\n                if p.stdout in rfd:\n                    chunk = p.stdout.read()\n                elif p.stderr in rfd:\n                    chunk = p.stderr.read()\n                else:\n                    stdout, stderr = p.communicate()\n                    raise errors.AnsibleError('timeout waiting for sudo password prompt:\\n' + sudo_output)\n                if not chunk:\n                    stdout, stderr = p.communicate()\n                    raise errors.AnsibleError('sudo output closed while waiting for password prompt:\\n' + sudo_output)\n                sudo_output += chunk\n            if success_key not in sudo_output:\n                p.stdin.write(self.runner.sudo_pass + '\\n')\n            fcntl.fcntl(p.stdout, fcntl.F_SETFL, fcntl.fcntl(p.stdout, fcntl.F_GETFL) & ~os.O_NONBLOCK)\n            fcntl.fcntl(p.stderr, fcntl.F_SETFL, fcntl.fcntl(p.stderr, fcntl.F_GETFL) & ~os.O_NONBLOCK)\n\n        stdout, stderr = p.communicate()\n        return (p.returncode, '', stdout, stderr)\n\n    def put_file(self, in_path, out_path):\n        ''' transfer a file from local to local '''\n\n        vvv(\"PUT %s TO %s\" % (in_path, out_path), host=self.host)\n        if not os.path.exists(in_path):\n            raise errors.AnsibleFileNotFound(\"file or module does not exist: %s\" % in_path)\n        try:\n            shutil.copyfile(in_path, out_path)\n        except shutil.Error:\n            traceback.print_exc()\n            raise errors.AnsibleError(\"failed to copy: %s and %s are the same\" % (in_path, out_path))\n        except IOError:\n            traceback.print_exc()\n            raise errors.AnsibleError(\"failed to transfer file to %s\" % out_path)\n\n    def fetch_file(self, in_path, out_path):\n        vvv(\"FETCH %s TO %s\" % (in_path, out_path), host=self.host)\n        ''' fetch a file from local to local -- for copatibility '''\n        self.put_file(in_path, out_path)\n\n    def close(self):\n        ''' terminate the connection; nothing to do here '''\n        pass\n","markers":{"markers":{"1":{"id":1,"range":[[0,0],[0,0]],"tailed":false,"reversed":false,"valid":true,"invalidate":"never","persistent":true,"properties":{"type":"selection","editorId":269},"deserializer":"Marker"}},"deserializer":"MarkerManager"},"history":{"undoStack":[],"redoStack":[],"deserializer":"History"},"filePath":"/Users/etrikp/git/ansible/lib/ansible/runner/connection_plugins/local.py","modifiedWhenLastPersisted":false,"digestWhenLastPersisted":"97550224add460c0c7cf6bf99d65f44bc1025eaf","deserializer":"TextBuffer"},{"text":"# (c) 2012, Michael DeHaan <michael.dehaan@gmail.com>\n#\n# This file is part of Ansible\n#\n# Ansible is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# Ansible is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.\n\nimport json\nimport os\nimport base64\nfrom ansible.callbacks import vvv\nfrom ansible import utils\nfrom ansible import errors\nfrom ansible import constants\n\nHAVE_ZMQ=False\n\ntry:\n    import zmq\n    HAVE_ZMQ=True\nexcept ImportError:\n    pass\n\nclass Connection(object):\n    ''' ZeroMQ accelerated connection '''\n\n    def __init__(self, runner, host, port, *args, **kwargs):\n\n        self.runner = runner\n        self.has_pipelining = False\n\n        # attempt to work around shared-memory funness\n        if getattr(self.runner, 'aes_keys', None):\n            utils.AES_KEYS = self.runner.aes_keys\n\n        self.host = host\n        self.key = utils.key_for_hostname(host)\n        self.context = None\n        self.socket = None\n\n        if  port is None:\n            self.port = constants.ZEROMQ_PORT\n        else:\n            self.port = port\n\n    def connect(self):\n        ''' activates the connection object '''\n\n        if not HAVE_ZMQ:\n            raise errors.AnsibleError(\"zmq is not installed\")\n        \n        # this is rough/temporary and will likely be optimized later ...\n        self.context = zmq.Context()\n        socket = self.context.socket(zmq.REQ)\n        addr = \"tcp://%s:%s\" % (self.host, self.port)\n        socket.connect(addr)\n        self.socket = socket    \n\n        return self\n\n    def exec_command(self, cmd, tmp_path, sudo_user, sudoable=False, executable='/bin/sh', in_data=None, su_user=None, su=None):\n        ''' run a command on the remote host '''\n\n        if in_data:\n            raise errors.AnsibleError(\"Internal Error: this module does not support optimized module pipelining\")\n\n        vvv(\"EXEC COMMAND %s\" % cmd)\n\n        if (self.runner.sudo and sudoable) or (self.runner.su and su):\n            raise errors.AnsibleError(\n                \"When using fireball, do not specify sudo or su to run your tasks. \" +\n                \"Instead sudo the fireball action with sudo. \" +\n                \"Task will communicate with the fireball already running in sudo mode.\"\n            )\n\n        data = dict(\n            mode='command',\n            cmd=cmd,\n            tmp_path=tmp_path,\n            executable=executable,\n        )\n        data = utils.jsonify(data)\n        data = utils.encrypt(self.key, data)\n        self.socket.send(data)\n        \n        response = self.socket.recv()\n        response = utils.decrypt(self.key, response)\n        response = utils.parse_json(response)\n\n        return (response.get('rc',None), '', response.get('stdout',''), response.get('stderr',''))\n\n    def put_file(self, in_path, out_path):\n\n        ''' transfer a file from local to remote '''\n        vvv(\"PUT %s TO %s\" % (in_path, out_path), host=self.host)\n\n        if not os.path.exists(in_path):\n            raise errors.AnsibleFileNotFound(\"file or module does not exist: %s\" % in_path)\n        data = file(in_path).read()\n        data = base64.b64encode(data)\n\n        data = dict(mode='put', data=data, out_path=out_path)\n        # TODO: support chunked file transfer\n        data = utils.jsonify(data)\n        data = utils.encrypt(self.key, data)\n        self.socket.send(data)\n\n        response = self.socket.recv()\n        response = utils.decrypt(self.key, response)\n        response = utils.parse_json(response)\n\n        # no meaningful response needed for this\n\n    def fetch_file(self, in_path, out_path):\n        ''' save a remote file to the specified path '''\n        vvv(\"FETCH %s TO %s\" % (in_path, out_path), host=self.host)\n\n        data = dict(mode='fetch', in_path=in_path)\n        data = utils.jsonify(data)\n        data = utils.encrypt(self.key, data)\n        self.socket.send(data)\n\n        response = self.socket.recv()\n        response = utils.decrypt(self.key, response)\n        response = utils.parse_json(response)\n        response = response['data']\n        response = base64.b64decode(response)        \n\n        fh = open(out_path, \"w\")\n        fh.write(response)\n        fh.close()\n\n    def close(self):\n        ''' terminate the connection '''\n        # Be a good citizen\n        try:\n            self.socket.close()\n            self.context.term()\n        except:\n            pass\n\n","markers":{"markers":{"1":{"id":1,"range":[[0,0],[0,0]],"tailed":false,"reversed":false,"valid":true,"invalidate":"never","persistent":true,"properties":{"type":"selection","editorId":273},"deserializer":"Marker"}},"deserializer":"MarkerManager"},"history":{"undoStack":[],"redoStack":[],"deserializer":"History"},"filePath":"/Users/etrikp/git/ansible/lib/ansible/runner/connection_plugins/fireball.py","modifiedWhenLastPersisted":false,"digestWhenLastPersisted":"df2484b950811afa2228224931e73b4ce7158664","deserializer":"TextBuffer"}],"deserializer":"Project"},"workspace":{"paneContainer":{"root":{"id":3,"items":[{"id":182,"softTabs":true,"displayBuffer":{"id":183,"softWrap":false,"editorWidthInChars":null,"scrollTop":0,"scrollLeft":0,"tokenizedBuffer":{"bufferPath":"/Users/etrikp/git/ansible/lib/ansible/module_utils/openstack.py","tabLength":2,"deserializer":"TokenizedBuffer"},"deserializer":"DisplayBuffer"},"deserializer":"Editor"},{"id":186,"softTabs":true,"displayBuffer":{"id":187,"softWrap":false,"editorWidthInChars":null,"scrollTop":1953,"scrollLeft":0,"tokenizedBuffer":{"bufferPath":"/Users/etrikp/git/ansible/lib/ansible/module_utils/facts.py","tabLength":2,"deserializer":"TokenizedBuffer"},"deserializer":"DisplayBuffer"},"deserializer":"Editor"},{"id":236,"softTabs":true,"displayBuffer":{"id":237,"softWrap":false,"editorWidthInChars":null,"scrollTop":3175,"scrollLeft":0,"tokenizedBuffer":{"bufferPath":"/Users/etrikp/git/ansible/lib/ansible/runner/action_plugins/synchronize.py","tabLength":2,"deserializer":"TokenizedBuffer"},"deserializer":"DisplayBuffer"},"deserializer":"Editor"},{"id":240,"softTabs":true,"displayBuffer":{"id":241,"softWrap":false,"editorWidthInChars":null,"scrollTop":1075,"scrollLeft":0,"tokenizedBuffer":{"bufferPath":"/Users/etrikp/git/ansible/lib/ansible/runner/action_plugins/group_by.py","tabLength":2,"deserializer":"TokenizedBuffer"},"deserializer":"DisplayBuffer"},"deserializer":"Editor"},{"id":244,"softTabs":true,"displayBuffer":{"id":245,"softWrap":false,"editorWidthInChars":null,"scrollTop":6395,"scrollLeft":0,"tokenizedBuffer":{"bufferPath":"/Users/etrikp/git/ansible/lib/ansible/runner/action_plugins/copy.py","tabLength":2,"deserializer":"TokenizedBuffer"},"deserializer":"DisplayBuffer"},"deserializer":"Editor"},{"id":248,"softTabs":true,"displayBuffer":{"id":249,"softWrap":false,"editorWidthInChars":null,"scrollTop":0,"scrollLeft":0,"tokenizedBuffer":{"bufferPath":"/Users/etrikp/git/ansible/lib/ansible/runner/action_plugins/assemble.py","tabLength":2,"deserializer":"TokenizedBuffer"},"deserializer":"DisplayBuffer"},"deserializer":"Editor"},{"id":265,"softTabs":true,"displayBuffer":{"id":266,"softWrap":false,"editorWidthInChars":null,"scrollTop":0,"scrollLeft":0,"tokenizedBuffer":{"bufferPath":"/Users/etrikp/git/ansible/lib/ansible/runner/connection_plugins/libvirt_lxc.py","tabLength":2,"deserializer":"TokenizedBuffer"},"deserializer":"DisplayBuffer"},"deserializer":"Editor"},{"id":269,"softTabs":true,"displayBuffer":{"id":270,"softWrap":false,"editorWidthInChars":null,"scrollTop":0,"scrollLeft":0,"tokenizedBuffer":{"bufferPath":"/Users/etrikp/git/ansible/lib/ansible/runner/connection_plugins/local.py","tabLength":2,"deserializer":"TokenizedBuffer"},"deserializer":"DisplayBuffer"},"deserializer":"Editor"},{"id":273,"softTabs":true,"displayBuffer":{"id":274,"softWrap":false,"editorWidthInChars":null,"scrollTop":1207,"scrollLeft":0,"tokenizedBuffer":{"bufferPath":"/Users/etrikp/git/ansible/lib/ansible/runner/connection_plugins/fireball.py","tabLength":2,"deserializer":"TokenizedBuffer"},"deserializer":"DisplayBuffer"},"deserializer":"Editor"}],"activeItemUri":"/Users/etrikp/git/ansible/lib/ansible/runner/connection_plugins/fireball.py","focused":false,"deserializer":"Pane"},"activePaneId":3,"deserializer":"PaneContainer","version":1},"fullScreen":false,"packagesWithActiveGrammars":["language-python","language-hyperlink","language-todo"],"deserializer":"Workspace"},"packageStates":{"fuzzy-finder":{"/Users/etrikp/git/ansible/lib/ansible/module_utils/openstack.py":1410413774467,"/Users/etrikp/git/ansible/lib/ansible/module_utils/facts.py":1410413816571,"/Users/etrikp/git/ansible/lib/ansible/runner/action_plugins/synchronize.py":1410413841702,"/Users/etrikp/git/ansible/lib/ansible/runner/action_plugins/group_by.py":1410414000393,"/Users/etrikp/git/ansible/lib/ansible/runner/action_plugins/copy.py":1410414007705,"/Users/etrikp/git/ansible/lib/ansible/runner/action_plugins/assemble.py":1410414013208,"/Users/etrikp/git/ansible/lib/ansible/runner/connection_plugins/libvirt_lxc.py":1410414025205,"/Users/etrikp/git/ansible/lib/ansible/runner/connection_plugins/local.py":1410414034352,"/Users/etrikp/git/ansible/lib/ansible/runner/connection_plugins/fireball.py":1410414038351},"keybinding-resolver":{"attached":false},"metrics":{"sessionLength":56760534},"tree-view":{"directoryExpansionStates":{},"selectedPath":"/Users/etrikp/git/ansible/lib","hasFocus":true,"attached":true,"scrollLeft":0,"scrollTop":0,"width":344}}}